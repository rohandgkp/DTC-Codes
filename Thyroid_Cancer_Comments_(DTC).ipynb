{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDQ5IeSME0IJ",
        "outputId": "8be67846-415b-411c-faae-b18177571862"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2026.1.4)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install ucimlrepo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "differentiated_thyroid_cancer_recurrence = fetch_ucirepo(id=915)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = differentiated_thyroid_cancer_recurrence.data.features\n",
        "y = differentiated_thyroid_cancer_recurrence.data.targets\n",
        "\n",
        "# metadata\n",
        "#print(differentiated_thyroid_cancer_recurrence.metadata)\n",
        "\n",
        "# variable information\n",
        "print(differentiated_thyroid_cancer_recurrence.variables)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hfvnA9eFXv3",
        "outputId": "8703f0e3-f887-45b9-a837-77e071986c0d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    name     role         type demographic description units  \\\n",
            "0                    Age  Feature      Integer         Age        None  None   \n",
            "1                 Gender  Feature  Categorical      Gender        None  None   \n",
            "2                Smoking  Feature  Categorical        None        None  None   \n",
            "3             Hx Smoking  Feature  Categorical        None        None  None   \n",
            "4        Hx Radiothreapy  Feature  Categorical        None        None  None   \n",
            "5       Thyroid Function  Feature  Categorical        None        None  None   \n",
            "6   Physical Examination  Feature  Categorical        None        None  None   \n",
            "7             Adenopathy  Feature  Categorical        None        None  None   \n",
            "8              Pathology  Feature  Categorical        None        None  None   \n",
            "9               Focality  Feature  Categorical        None        None  None   \n",
            "10                  Risk  Feature  Categorical        None        None  None   \n",
            "11                     T  Feature  Categorical        None        None  None   \n",
            "12                     N  Feature  Categorical        None        None  None   \n",
            "13                     M  Feature  Categorical        None        None  None   \n",
            "14                 Stage  Feature  Categorical        None        None  None   \n",
            "15              Response  Feature  Categorical        None        None  None   \n",
            "16              Recurred   Target  Categorical        None        None  None   \n",
            "\n",
            "   missing_values  \n",
            "0              no  \n",
            "1              no  \n",
            "2              no  \n",
            "3              no  \n",
            "4              no  \n",
            "5              no  \n",
            "6              no  \n",
            "7              no  \n",
            "8              no  \n",
            "9              no  \n",
            "10             no  \n",
            "11             no  \n",
            "12             no  \n",
            "13             no  \n",
            "14             no  \n",
            "15             no  \n",
            "16             no  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftwJirFlFgJS",
        "outputId": "2f9b68fc-707f-40e0-d85e-8122351d6f00"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 383 entries, 0 to 382\n",
            "Data columns (total 16 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   Age                   383 non-null    int64 \n",
            " 1   Gender                383 non-null    object\n",
            " 2   Smoking               383 non-null    object\n",
            " 3   Hx Smoking            383 non-null    object\n",
            " 4   Hx Radiothreapy       383 non-null    object\n",
            " 5   Thyroid Function      383 non-null    object\n",
            " 6   Physical Examination  383 non-null    object\n",
            " 7   Adenopathy            383 non-null    object\n",
            " 8   Pathology             383 non-null    object\n",
            " 9   Focality              383 non-null    object\n",
            " 10  Risk                  383 non-null    object\n",
            " 11  T                     383 non-null    object\n",
            " 12  N                     383 non-null    object\n",
            " 13  M                     383 non-null    object\n",
            " 14  Stage                 383 non-null    object\n",
            " 15  Response              383 non-null    object\n",
            "dtypes: int64(1), object(15)\n",
            "memory usage: 48.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yx4OSmtlFiIH",
        "outputId": "119c2778-f057-4820-cb38-158cb90ac79e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 383 entries, 0 to 382\n",
            "Data columns (total 1 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   Recurred  383 non-null    object\n",
            "dtypes: object(1)\n",
            "memory usage: 3.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**One-Hot Encoding**"
      ],
      "metadata": {
        "id": "P78iqREpFkKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# One-hot encode all categorical columns (drop_first=True avoids multicollinearity)\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Optionally encode the target variable too (if needed for ML)\n",
        "y = y.copy()\n",
        "y['Recurred'] = y['Recurred'].map({'No': 0, 'Yes': 1})  # adjust if labels differ\n"
      ],
      "metadata": {
        "id": "21OKRk5CFoXV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irBtTJ70Fsgs",
        "outputId": "6c74fe2e-9530-4aea-d360-8b9ad29b37f6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 383 entries, 0 to 382\n",
            "Data columns (total 40 columns):\n",
            " #   Column                                            Non-Null Count  Dtype\n",
            "---  ------                                            --------------  -----\n",
            " 0   Age                                               383 non-null    int64\n",
            " 1   Gender_M                                          383 non-null    bool \n",
            " 2   Smoking_Yes                                       383 non-null    bool \n",
            " 3   Hx Smoking_Yes                                    383 non-null    bool \n",
            " 4   Hx Radiothreapy_Yes                               383 non-null    bool \n",
            " 5   Thyroid Function_Clinical Hypothyroidism          383 non-null    bool \n",
            " 6   Thyroid Function_Euthyroid                        383 non-null    bool \n",
            " 7   Thyroid Function_Subclinical Hyperthyroidism      383 non-null    bool \n",
            " 8   Thyroid Function_Subclinical Hypothyroidism       383 non-null    bool \n",
            " 9   Physical Examination_Multinodular goiter          383 non-null    bool \n",
            " 10  Physical Examination_Normal                       383 non-null    bool \n",
            " 11  Physical Examination_Single nodular goiter-left   383 non-null    bool \n",
            " 12  Physical Examination_Single nodular goiter-right  383 non-null    bool \n",
            " 13  Adenopathy_Extensive                              383 non-null    bool \n",
            " 14  Adenopathy_Left                                   383 non-null    bool \n",
            " 15  Adenopathy_No                                     383 non-null    bool \n",
            " 16  Adenopathy_Posterior                              383 non-null    bool \n",
            " 17  Adenopathy_Right                                  383 non-null    bool \n",
            " 18  Pathology_Hurthel cell                            383 non-null    bool \n",
            " 19  Pathology_Micropapillary                          383 non-null    bool \n",
            " 20  Pathology_Papillary                               383 non-null    bool \n",
            " 21  Focality_Uni-Focal                                383 non-null    bool \n",
            " 22  Risk_Intermediate                                 383 non-null    bool \n",
            " 23  Risk_Low                                          383 non-null    bool \n",
            " 24  T_T1b                                             383 non-null    bool \n",
            " 25  T_T2                                              383 non-null    bool \n",
            " 26  T_T3a                                             383 non-null    bool \n",
            " 27  T_T3b                                             383 non-null    bool \n",
            " 28  T_T4a                                             383 non-null    bool \n",
            " 29  T_T4b                                             383 non-null    bool \n",
            " 30  N_N1a                                             383 non-null    bool \n",
            " 31  N_N1b                                             383 non-null    bool \n",
            " 32  M_M1                                              383 non-null    bool \n",
            " 33  Stage_II                                          383 non-null    bool \n",
            " 34  Stage_III                                         383 non-null    bool \n",
            " 35  Stage_IVA                                         383 non-null    bool \n",
            " 36  Stage_IVB                                         383 non-null    bool \n",
            " 37  Response_Excellent                                383 non-null    bool \n",
            " 38  Response_Indeterminate                            383 non-null    bool \n",
            " 39  Response_Structural Incomplete                    383 non-null    bool \n",
            "dtypes: bool(39), int64(1)\n",
            "memory usage: 17.7 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbJWPpbeFuvN",
        "outputId": "256f6603-11fe-4ad9-f55d-98d4c2fd4046"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 383 entries, 0 to 382\n",
            "Data columns (total 1 columns):\n",
            " #   Column    Non-Null Count  Dtype\n",
            "---  ------    --------------  -----\n",
            " 0   Recurred  383 non-null    int64\n",
            "dtypes: int64(1)\n",
            "memory usage: 3.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iWh_q3JpFwcm",
        "outputId": "48aec446-f23e-4d29-d1cf-e7fff9f36f88"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Age                                                 0\n",
              "Gender_M                                            0\n",
              "Smoking_Yes                                         0\n",
              "Hx Smoking_Yes                                      0\n",
              "Hx Radiothreapy_Yes                                 0\n",
              "Thyroid Function_Clinical Hypothyroidism            0\n",
              "Thyroid Function_Euthyroid                          0\n",
              "Thyroid Function_Subclinical Hyperthyroidism        0\n",
              "Thyroid Function_Subclinical Hypothyroidism         0\n",
              "Physical Examination_Multinodular goiter            0\n",
              "Physical Examination_Normal                         0\n",
              "Physical Examination_Single nodular goiter-left     0\n",
              "Physical Examination_Single nodular goiter-right    0\n",
              "Adenopathy_Extensive                                0\n",
              "Adenopathy_Left                                     0\n",
              "Adenopathy_No                                       0\n",
              "Adenopathy_Posterior                                0\n",
              "Adenopathy_Right                                    0\n",
              "Pathology_Hurthel cell                              0\n",
              "Pathology_Micropapillary                            0\n",
              "Pathology_Papillary                                 0\n",
              "Focality_Uni-Focal                                  0\n",
              "Risk_Intermediate                                   0\n",
              "Risk_Low                                            0\n",
              "T_T1b                                               0\n",
              "T_T2                                                0\n",
              "T_T3a                                               0\n",
              "T_T3b                                               0\n",
              "T_T4a                                               0\n",
              "T_T4b                                               0\n",
              "N_N1a                                               0\n",
              "N_N1b                                               0\n",
              "M_M1                                                0\n",
              "Stage_II                                            0\n",
              "Stage_III                                           0\n",
              "Stage_IVA                                           0\n",
              "Stage_IVB                                           0\n",
              "Response_Excellent                                  0\n",
              "Response_Indeterminate                              0\n",
              "Response_Structural Incomplete                      0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gender_M</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Smoking_Yes</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hx Smoking_Yes</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hx Radiothreapy_Yes</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Thyroid Function_Clinical Hypothyroidism</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Thyroid Function_Euthyroid</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Thyroid Function_Subclinical Hyperthyroidism</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Thyroid Function_Subclinical Hypothyroidism</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Physical Examination_Multinodular goiter</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Physical Examination_Normal</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Physical Examination_Single nodular goiter-left</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Physical Examination_Single nodular goiter-right</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adenopathy_Extensive</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adenopathy_Left</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adenopathy_No</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adenopathy_Posterior</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Adenopathy_Right</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pathology_Hurthel cell</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pathology_Micropapillary</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pathology_Papillary</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Focality_Uni-Focal</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Risk_Intermediate</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Risk_Low</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T_T1b</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T_T2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T_T3a</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T_T3b</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T_T4a</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T_T4b</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>N_N1a</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>N_N1b</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>M_M1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stage_II</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stage_III</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stage_IVA</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Stage_IVB</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Response_Excellent</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Response_Indeterminate</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Response_Structural Incomplete</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "tThEsJF3F1Ut",
        "outputId": "a554d803-0fae-4c36-d2c9-39907cf50fc6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Recurred    0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Recurred</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LR**"
      ],
      "metadata": {
        "id": "QBuwY0A0GC5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = LogisticRegression(\n",
        "        max_iter=1000,\n",
        "        random_state=42,\n",
        "        class_weight='balanced'\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYCglRCXF5Hg",
        "outputId": "c4207087-4210-462d-c37f-ff846ce07194"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({'Recurred': 1})\n",
            "After SMOTE-Tomek:  Counter({'Recurred': 1})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[85  7]\n",
            " [ 2 34]]\n",
            "Accuracy: 0.9297\n",
            "Precision: 0.8293\n",
            "Recall (Sensitivity): 0.9444\n",
            "Specificity: 0.9239\n",
            "F1-score: 0.8831\n",
            "AUC-ROC: 0.9683\n",
            "AUPRC: 0.9680\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({'Recurred': 1})\n",
            "After SMOTE-Tomek:  Counter({'Recurred': 1})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[89  3]\n",
            " [ 4 32]]\n",
            "Accuracy: 0.9453\n",
            "Precision: 0.9143\n",
            "Recall (Sensitivity): 0.8889\n",
            "Specificity: 0.9674\n",
            "F1-score: 0.9014\n",
            "AUC-ROC: 0.9701\n",
            "AUPRC: 0.8912\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({'Recurred': 1})\n",
            "After SMOTE-Tomek:  Counter({'Recurred': 1})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[89  2]\n",
            " [ 4 32]]\n",
            "Accuracy: 0.9528\n",
            "Precision: 0.9412\n",
            "Recall (Sensitivity): 0.8889\n",
            "Specificity: 0.9780\n",
            "F1-score: 0.9143\n",
            "AUC-ROC: 0.9664\n",
            "AUPRC: 0.9651\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.9426 ± 0.0118\n",
            "Precision: 0.8949 ± 0.0584\n",
            "Recall (Sensitivity): 0.9074 ± 0.0321\n",
            "Specificity: 0.9564 ± 0.0287\n",
            "F1-score: 0.8996 ± 0.0157\n",
            "AUC-ROC: 0.9683 ± 0.0018\n",
            "AUPRC: 0.9414 ± 0.0436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RF**"
      ],
      "metadata": {
        "id": "ohufawhlJIdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
        "\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pulRYyylJKLr",
        "outputId": "0e9e37a6-0728-451b-a9e6-a9bdf9866ab2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({'Recurred': 1})\n",
            "After SMOTE-Tomek:  Counter({'Recurred': 1})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[55  0]\n",
            " [ 1 21]]\n",
            "Accuracy: 0.9870\n",
            "Precision: 1.0000\n",
            "Recall (Sensitivity): 0.9545\n",
            "Specificity: 1.0000\n",
            "F1-score: 0.9767\n",
            "AUC-ROC: 0.9926\n",
            "AUPRC: 0.9868\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({'Recurred': 1})\n",
            "After SMOTE-Tomek:  Counter({'Recurred': 1})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[53  2]\n",
            " [ 2 20]]\n",
            "Accuracy: 0.9481\n",
            "Precision: 0.9091\n",
            "Recall (Sensitivity): 0.9091\n",
            "Specificity: 0.9636\n",
            "F1-score: 0.9091\n",
            "AUC-ROC: 0.9760\n",
            "AUPRC: 0.9576\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({'Recurred': 1})\n",
            "After SMOTE-Tomek:  Counter({'Recurred': 1})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[52  3]\n",
            " [ 2 20]]\n",
            "Accuracy: 0.9351\n",
            "Precision: 0.8696\n",
            "Recall (Sensitivity): 0.9091\n",
            "Specificity: 0.9455\n",
            "F1-score: 0.8889\n",
            "AUC-ROC: 0.9893\n",
            "AUPRC: 0.9781\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({'Recurred': 1})\n",
            "After SMOTE-Tomek:  Counter({'Recurred': 1})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[53  2]\n",
            " [ 1 20]]\n",
            "Accuracy: 0.9605\n",
            "Precision: 0.9091\n",
            "Recall (Sensitivity): 0.9524\n",
            "Specificity: 0.9636\n",
            "F1-score: 0.9302\n",
            "AUC-ROC: 0.9983\n",
            "AUPRC: 0.9959\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({'Recurred': 1})\n",
            "After SMOTE-Tomek:  Counter({'Recurred': 1})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[53  2]\n",
            " [ 6 15]]\n",
            "Accuracy: 0.8947\n",
            "Precision: 0.8824\n",
            "Recall (Sensitivity): 0.7143\n",
            "Specificity: 0.9636\n",
            "F1-score: 0.7895\n",
            "AUC-ROC: 0.9835\n",
            "AUPRC: 0.9603\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.9451 ± 0.0341\n",
            "Precision: 0.9140 ± 0.0510\n",
            "Recall (Sensitivity): 0.8879 ± 0.0995\n",
            "Specificity: 0.9673 ± 0.0199\n",
            "F1-score: 0.8989 ± 0.0693\n",
            "AUC-ROC: 0.9879 ± 0.0085\n",
            "AUPRC: 0.9757 ± 0.0166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**KNN**"
      ],
      "metadata": {
        "id": "DhwvKhdXJjTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pbYdS9EJlNi",
        "outputId": "6b4fb14b-a91c-42c6-b60c-cc5cc81e907b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[54  1]\n",
            " [ 4 18]]\n",
            "Accuracy: 0.9351\n",
            "Precision: 0.9474\n",
            "Recall (Sensitivity): 0.8182\n",
            "Specificity: 0.9818\n",
            "F1-score: 0.8780\n",
            "AUC-ROC: 0.9599\n",
            "AUPRC: 0.9219\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 219, 1: 219})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[50  5]\n",
            " [ 2 20]]\n",
            "Accuracy: 0.9091\n",
            "Precision: 0.8000\n",
            "Recall (Sensitivity): 0.9091\n",
            "Specificity: 0.9091\n",
            "F1-score: 0.8511\n",
            "AUC-ROC: 0.9426\n",
            "AUPRC: 0.8605\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[53  2]\n",
            " [ 3 19]]\n",
            "Accuracy: 0.9351\n",
            "Precision: 0.9048\n",
            "Recall (Sensitivity): 0.8636\n",
            "Specificity: 0.9636\n",
            "F1-score: 0.8837\n",
            "AUC-ROC: 0.9607\n",
            "AUPRC: 0.9333\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 87})\n",
            "After SMOTE-Tomek:  Counter({0: 219, 1: 219})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[53  2]\n",
            " [ 4 17]]\n",
            "Accuracy: 0.9211\n",
            "Precision: 0.8947\n",
            "Recall (Sensitivity): 0.8095\n",
            "Specificity: 0.9636\n",
            "F1-score: 0.8500\n",
            "AUC-ROC: 0.9706\n",
            "AUPRC: 0.8946\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 87})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[50  5]\n",
            " [ 3 18]]\n",
            "Accuracy: 0.8947\n",
            "Precision: 0.7826\n",
            "Recall (Sensitivity): 0.8571\n",
            "Specificity: 0.9091\n",
            "F1-score: 0.8182\n",
            "AUC-ROC: 0.9641\n",
            "AUPRC: 0.8845\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.9190 ± 0.0174\n",
            "Precision: 0.8659 ± 0.0712\n",
            "Recall (Sensitivity): 0.8515 ± 0.0399\n",
            "Specificity: 0.9455 ± 0.0340\n",
            "F1-score: 0.8562 ± 0.0262\n",
            "AUC-ROC: 0.9596 ± 0.0104\n",
            "AUPRC: 0.8989 ± 0.0292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GNB**"
      ],
      "metadata": {
        "id": "d1cMPVNNJ4QG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = GaussianNB()\n",
        "\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2l8e9YS6J6YD",
        "outputId": "2f9e0093-7b01-4209-ee0d-e40962ed2864"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[55  0]\n",
            " [ 9 13]]\n",
            "Accuracy: 0.8831\n",
            "Precision: 1.0000\n",
            "Recall (Sensitivity): 0.5909\n",
            "Specificity: 1.0000\n",
            "F1-score: 0.7429\n",
            "AUC-ROC: 0.9967\n",
            "AUPRC: 0.9925\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 219, 1: 219})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[53  2]\n",
            " [ 4 18]]\n",
            "Accuracy: 0.9221\n",
            "Precision: 0.9000\n",
            "Recall (Sensitivity): 0.8182\n",
            "Specificity: 0.9636\n",
            "F1-score: 0.8571\n",
            "AUC-ROC: 0.9678\n",
            "AUPRC: 0.8842\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[53  2]\n",
            " [ 4 18]]\n",
            "Accuracy: 0.9221\n",
            "Precision: 0.9000\n",
            "Recall (Sensitivity): 0.8182\n",
            "Specificity: 0.9636\n",
            "F1-score: 0.8571\n",
            "AUC-ROC: 0.9636\n",
            "AUPRC: 0.8759\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 87})\n",
            "After SMOTE-Tomek:  Counter({0: 219, 1: 219})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[55  0]\n",
            " [ 5 16]]\n",
            "Accuracy: 0.9342\n",
            "Precision: 1.0000\n",
            "Recall (Sensitivity): 0.7619\n",
            "Specificity: 1.0000\n",
            "F1-score: 0.8649\n",
            "AUC-ROC: 0.9896\n",
            "AUPRC: 0.9749\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 87})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[54  1]\n",
            " [ 7 14]]\n",
            "Accuracy: 0.8947\n",
            "Precision: 0.9333\n",
            "Recall (Sensitivity): 0.6667\n",
            "Specificity: 0.9818\n",
            "F1-score: 0.7778\n",
            "AUC-ROC: 0.9580\n",
            "AUPRC: 0.9328\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.9112 ± 0.0214\n",
            "Precision: 0.9467 ± 0.0506\n",
            "Recall (Sensitivity): 0.7312 ± 0.0999\n",
            "Specificity: 0.9818 ± 0.0182\n",
            "F1-score: 0.8200 ± 0.0559\n",
            "AUC-ROC: 0.9751 ± 0.0170\n",
            "AUPRC: 0.9320 ± 0.0523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MLP**"
      ],
      "metadata": {
        "id": "rkc3MULKKMyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = MLPClassifier(hidden_layer_sizes=(150, 100, 50), max_iter=1000, random_state=42)\n",
        "\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnRYL-NFKOeD",
        "outputId": "7b797534-50e9-425b-c85b-077ea28c9b44"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[52  3]\n",
            " [ 1 21]]\n",
            "Accuracy: 0.9481\n",
            "Precision: 0.8750\n",
            "Recall (Sensitivity): 0.9545\n",
            "Specificity: 0.9455\n",
            "F1-score: 0.9130\n",
            "AUC-ROC: 0.9835\n",
            "AUPRC: 0.9745\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 219, 1: 219})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[54  1]\n",
            " [ 2 20]]\n",
            "Accuracy: 0.9610\n",
            "Precision: 0.9524\n",
            "Recall (Sensitivity): 0.9091\n",
            "Specificity: 0.9818\n",
            "F1-score: 0.9302\n",
            "AUC-ROC: 0.9628\n",
            "AUPRC: 0.9443\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[53  2]\n",
            " [ 2 20]]\n",
            "Accuracy: 0.9481\n",
            "Precision: 0.9091\n",
            "Recall (Sensitivity): 0.9091\n",
            "Specificity: 0.9636\n",
            "F1-score: 0.9091\n",
            "AUC-ROC: 0.9868\n",
            "AUPRC: 0.9784\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 87})\n",
            "After SMOTE-Tomek:  Counter({0: 219, 1: 219})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[53  2]\n",
            " [ 2 19]]\n",
            "Accuracy: 0.9474\n",
            "Precision: 0.9048\n",
            "Recall (Sensitivity): 0.9048\n",
            "Specificity: 0.9636\n",
            "F1-score: 0.9048\n",
            "AUC-ROC: 0.9732\n",
            "AUPRC: 0.9604\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 87})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[52  3]\n",
            " [ 5 16]]\n",
            "Accuracy: 0.8947\n",
            "Precision: 0.8421\n",
            "Recall (Sensitivity): 0.7619\n",
            "Specificity: 0.9455\n",
            "F1-score: 0.8000\n",
            "AUC-ROC: 0.9636\n",
            "AUPRC: 0.9299\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.9398 ± 0.0259\n",
            "Precision: 0.8967 ± 0.0411\n",
            "Recall (Sensitivity): 0.8879 ± 0.0733\n",
            "Specificity: 0.9600 ± 0.0152\n",
            "F1-score: 0.8914 ± 0.0520\n",
            "AUC-ROC: 0.9740 ± 0.0110\n",
            "AUPRC: 0.9575 ± 0.0204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XGB**"
      ],
      "metadata": {
        "id": "PTfnT8-oKmai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = XGBClassifier(\n",
        "        n_estimators=100,        # ↓ fewer trees\n",
        "        max_depth=3,             # ↓ shallow trees\n",
        "        learning_rate=0.05,      # ↓ slower learning\n",
        "        subsample=0.7,           # ↓ stochastic training\n",
        "        colsample_bytree=0.7,    # ↓ fewer features per tree\n",
        "        random_state=42,\n",
        "        eval_metric='logloss',\n",
        "        use_label_encoder=False\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K15D9CbfKoPD",
        "outputId": "f07b98b3-2f8a-4b39-9ae1-5347d94d514c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({'Recurred': 1})\n",
            "After SMOTE-Tomek:  Counter({'Recurred': 1})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[53  2]\n",
            " [ 1 21]]\n",
            "Accuracy: 0.9610\n",
            "Precision: 0.9130\n",
            "Recall (Sensitivity): 0.9545\n",
            "Specificity: 0.9636\n",
            "F1-score: 0.9333\n",
            "AUC-ROC: 0.9893\n",
            "AUPRC: 0.9819\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({'Recurred': 1})\n",
            "After SMOTE-Tomek:  Counter({'Recurred': 1})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[54  1]\n",
            " [ 2 20]]\n",
            "Accuracy: 0.9610\n",
            "Precision: 0.9524\n",
            "Recall (Sensitivity): 0.9091\n",
            "Specificity: 0.9818\n",
            "F1-score: 0.9302\n",
            "AUC-ROC: 0.9711\n",
            "AUPRC: 0.9385\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({'Recurred': 1})\n",
            "After SMOTE-Tomek:  Counter({'Recurred': 1})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[52  3]\n",
            " [ 2 20]]\n",
            "Accuracy: 0.9351\n",
            "Precision: 0.8696\n",
            "Recall (Sensitivity): 0.9091\n",
            "Specificity: 0.9455\n",
            "F1-score: 0.8889\n",
            "AUC-ROC: 0.9917\n",
            "AUPRC: 0.9821\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({'Recurred': 1})\n",
            "After SMOTE-Tomek:  Counter({'Recurred': 1})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[53  2]\n",
            " [ 1 20]]\n",
            "Accuracy: 0.9605\n",
            "Precision: 0.9091\n",
            "Recall (Sensitivity): 0.9524\n",
            "Specificity: 0.9636\n",
            "F1-score: 0.9302\n",
            "AUC-ROC: 0.9983\n",
            "AUPRC: 0.9959\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({'Recurred': 1})\n",
            "After SMOTE-Tomek:  Counter({'Recurred': 1})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[53  2]\n",
            " [ 4 17]]\n",
            "Accuracy: 0.9211\n",
            "Precision: 0.8947\n",
            "Recall (Sensitivity): 0.8095\n",
            "Specificity: 0.9636\n",
            "F1-score: 0.8500\n",
            "AUC-ROC: 0.9818\n",
            "AUPRC: 0.9600\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.9477 ± 0.0186\n",
            "Precision: 0.9078 ± 0.0302\n",
            "Recall (Sensitivity): 0.9069 ± 0.0588\n",
            "Specificity: 0.9636 ± 0.0129\n",
            "F1-score: 0.9065 ± 0.0366\n",
            "AUC-ROC: 0.9864 ± 0.0104\n",
            "AUPRC: 0.9717 ± 0.0226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ADB**"
      ],
      "metadata": {
        "id": "z8e5uJP4K686"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgYWs0hLK8r5",
        "outputId": "af3bdb4f-c8bf-4cc9-ac76-c21e788aca44"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[52  3]\n",
            " [ 1 21]]\n",
            "Accuracy: 0.9481\n",
            "Precision: 0.8750\n",
            "Recall (Sensitivity): 0.9545\n",
            "Specificity: 0.9455\n",
            "F1-score: 0.9130\n",
            "AUC-ROC: 0.9917\n",
            "AUPRC: 0.9858\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 219, 1: 219})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[54  1]\n",
            " [ 2 20]]\n",
            "Accuracy: 0.9610\n",
            "Precision: 0.9524\n",
            "Recall (Sensitivity): 0.9091\n",
            "Specificity: 0.9818\n",
            "F1-score: 0.9302\n",
            "AUC-ROC: 0.9752\n",
            "AUPRC: 0.9476\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[50  5]\n",
            " [ 3 19]]\n",
            "Accuracy: 0.8961\n",
            "Precision: 0.7917\n",
            "Recall (Sensitivity): 0.8636\n",
            "Specificity: 0.9091\n",
            "F1-score: 0.8261\n",
            "AUC-ROC: 0.9835\n",
            "AUPRC: 0.9650\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 87})\n",
            "After SMOTE-Tomek:  Counter({0: 219, 1: 219})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[55  0]\n",
            " [ 1 20]]\n",
            "Accuracy: 0.9868\n",
            "Precision: 1.0000\n",
            "Recall (Sensitivity): 0.9524\n",
            "Specificity: 1.0000\n",
            "F1-score: 0.9756\n",
            "AUC-ROC: 0.9771\n",
            "AUPRC: 0.9732\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 87})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[53  2]\n",
            " [ 2 19]]\n",
            "Accuracy: 0.9474\n",
            "Precision: 0.9048\n",
            "Recall (Sensitivity): 0.9048\n",
            "Specificity: 0.9636\n",
            "F1-score: 0.9048\n",
            "AUC-ROC: 0.9714\n",
            "AUPRC: 0.9530\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.9479 ± 0.0331\n",
            "Precision: 0.9048 ± 0.0791\n",
            "Recall (Sensitivity): 0.9169 ± 0.0378\n",
            "Specificity: 0.9600 ± 0.0350\n",
            "F1-score: 0.9099 ± 0.0543\n",
            "AUC-ROC: 0.9798 ± 0.0080\n",
            "AUPRC: 0.9649 ± 0.0154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GBC**"
      ],
      "metadata": {
        "id": "kGnb6PcoLsFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
        "\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdEiuNjULwY1",
        "outputId": "363fdd3e-c9da-414d-e119-c8cfdfc047ac"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[53  2]\n",
            " [ 1 21]]\n",
            "Accuracy: 0.9610\n",
            "Precision: 0.9130\n",
            "Recall (Sensitivity): 0.9545\n",
            "Specificity: 0.9636\n",
            "F1-score: 0.9333\n",
            "AUC-ROC: 0.9876\n",
            "AUPRC: 0.9768\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 219, 1: 219})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[54  1]\n",
            " [ 2 20]]\n",
            "Accuracy: 0.9610\n",
            "Precision: 0.9524\n",
            "Recall (Sensitivity): 0.9091\n",
            "Specificity: 0.9818\n",
            "F1-score: 0.9302\n",
            "AUC-ROC: 0.9727\n",
            "AUPRC: 0.9546\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[52  3]\n",
            " [ 2 20]]\n",
            "Accuracy: 0.9351\n",
            "Precision: 0.8696\n",
            "Recall (Sensitivity): 0.9091\n",
            "Specificity: 0.9455\n",
            "F1-score: 0.8889\n",
            "AUC-ROC: 0.9876\n",
            "AUPRC: 0.9722\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 87})\n",
            "After SMOTE-Tomek:  Counter({0: 219, 1: 219})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[53  2]\n",
            " [ 1 20]]\n",
            "Accuracy: 0.9605\n",
            "Precision: 0.9091\n",
            "Recall (Sensitivity): 0.9524\n",
            "Specificity: 0.9636\n",
            "F1-score: 0.9302\n",
            "AUC-ROC: 0.9983\n",
            "AUPRC: 0.9959\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 87})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[53  2]\n",
            " [ 3 18]]\n",
            "Accuracy: 0.9342\n",
            "Precision: 0.9000\n",
            "Recall (Sensitivity): 0.8571\n",
            "Specificity: 0.9636\n",
            "F1-score: 0.8780\n",
            "AUC-ROC: 0.9749\n",
            "AUPRC: 0.9493\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.9504 ± 0.0144\n",
            "Precision: 0.9088 ± 0.0297\n",
            "Recall (Sensitivity): 0.9165 ± 0.0399\n",
            "Specificity: 0.9636 ± 0.0129\n",
            "F1-score: 0.9121 ± 0.0265\n",
            "AUC-ROC: 0.9842 ± 0.0105\n",
            "AUPRC: 0.9697 ± 0.0186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ETC**"
      ],
      "metadata": {
        "id": "mPrZyYa9MM5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = ExtraTreesClassifier(n_estimators=100, max_depth=6, random_state=42)\n",
        "\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y37_-1eYMOxX",
        "outputId": "99977169-cfc1-4f01-f042-de7a4b22d5e1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({'Recurred': 1})\n",
            "After SMOTE-Tomek:  Counter({'Recurred': 1})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[55  0]\n",
            " [ 3 19]]\n",
            "Accuracy: 0.9610\n",
            "Precision: 1.0000\n",
            "Recall (Sensitivity): 0.8636\n",
            "Specificity: 1.0000\n",
            "F1-score: 0.9268\n",
            "AUC-ROC: 0.9909\n",
            "AUPRC: 0.9848\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({'Recurred': 1})\n",
            "After SMOTE-Tomek:  Counter({'Recurred': 1})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[53  2]\n",
            " [ 2 20]]\n",
            "Accuracy: 0.9481\n",
            "Precision: 0.9091\n",
            "Recall (Sensitivity): 0.9091\n",
            "Specificity: 0.9636\n",
            "F1-score: 0.9091\n",
            "AUC-ROC: 0.9793\n",
            "AUPRC: 0.9630\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({'Recurred': 1})\n",
            "After SMOTE-Tomek:  Counter({'Recurred': 1})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[54  1]\n",
            " [ 2 20]]\n",
            "Accuracy: 0.9610\n",
            "Precision: 0.9524\n",
            "Recall (Sensitivity): 0.9091\n",
            "Specificity: 0.9818\n",
            "F1-score: 0.9302\n",
            "AUC-ROC: 0.9909\n",
            "AUPRC: 0.9808\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({'Recurred': 1})\n",
            "After SMOTE-Tomek:  Counter({'Recurred': 1})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[54  1]\n",
            " [ 1 20]]\n",
            "Accuracy: 0.9737\n",
            "Precision: 0.9524\n",
            "Recall (Sensitivity): 0.9524\n",
            "Specificity: 0.9818\n",
            "F1-score: 0.9524\n",
            "AUC-ROC: 0.9974\n",
            "AUPRC: 0.9940\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({'Recurred': 1})\n",
            "After SMOTE-Tomek:  Counter({'Recurred': 1})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[54  1]\n",
            " [ 5 16]]\n",
            "Accuracy: 0.9211\n",
            "Precision: 0.9412\n",
            "Recall (Sensitivity): 0.7619\n",
            "Specificity: 0.9818\n",
            "F1-score: 0.8421\n",
            "AUC-ROC: 0.9835\n",
            "AUPRC: 0.9605\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.9530 ± 0.0200\n",
            "Precision: 0.9510 ± 0.0326\n",
            "Recall (Sensitivity): 0.8792 ± 0.0727\n",
            "Specificity: 0.9818 ± 0.0129\n",
            "F1-score: 0.9121 ± 0.0421\n",
            "AUC-ROC: 0.9884 ± 0.0071\n",
            "AUPRC: 0.9766 ± 0.0145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = ExtraTreesClassifier(\n",
        "        n_estimators=500,\n",
        "        max_depth=None,\n",
        "        criterion=\"gini\",\n",
        "        min_samples_split=2,\n",
        "        min_samples_leaf=1,\n",
        "        max_features=\"sqrt\",\n",
        "        class_weight=\"balanced_subsample\",\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mm2NTByNmC_m",
        "outputId": "f712cbaf-69e3-416a-9a80-3884e8388f1e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({'Recurred': 1})\n",
            "After SMOTE-Tomek:  Counter({'Recurred': 1})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[53  2]\n",
            " [ 2 20]]\n",
            "Accuracy: 0.9481\n",
            "Precision: 0.9091\n",
            "Recall (Sensitivity): 0.9091\n",
            "Specificity: 0.9636\n",
            "F1-score: 0.9091\n",
            "AUC-ROC: 0.9868\n",
            "AUPRC: 0.9759\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({'Recurred': 1})\n",
            "After SMOTE-Tomek:  Counter({'Recurred': 1})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[53  2]\n",
            " [ 2 20]]\n",
            "Accuracy: 0.9481\n",
            "Precision: 0.9091\n",
            "Recall (Sensitivity): 0.9091\n",
            "Specificity: 0.9636\n",
            "F1-score: 0.9091\n",
            "AUC-ROC: 0.9802\n",
            "AUPRC: 0.9688\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({'Recurred': 1})\n",
            "After SMOTE-Tomek:  Counter({'Recurred': 1})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[54  1]\n",
            " [ 2 20]]\n",
            "Accuracy: 0.9610\n",
            "Precision: 0.9524\n",
            "Recall (Sensitivity): 0.9091\n",
            "Specificity: 0.9818\n",
            "F1-score: 0.9302\n",
            "AUC-ROC: 0.9942\n",
            "AUPRC: 0.9869\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({'Recurred': 1})\n",
            "After SMOTE-Tomek:  Counter({'Recurred': 1})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[53  2]\n",
            " [ 1 20]]\n",
            "Accuracy: 0.9605\n",
            "Precision: 0.9091\n",
            "Recall (Sensitivity): 0.9524\n",
            "Specificity: 0.9636\n",
            "F1-score: 0.9302\n",
            "AUC-ROC: 0.9983\n",
            "AUPRC: 0.9959\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({'Recurred': 1})\n",
            "After SMOTE-Tomek:  Counter({'Recurred': 1})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[53  2]\n",
            " [ 6 15]]\n",
            "Accuracy: 0.8947\n",
            "Precision: 0.8824\n",
            "Recall (Sensitivity): 0.7143\n",
            "Specificity: 0.9636\n",
            "F1-score: 0.7895\n",
            "AUC-ROC: 0.9810\n",
            "AUPRC: 0.9541\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.9425 ± 0.0274\n",
            "Precision: 0.9124 ± 0.0252\n",
            "Recall (Sensitivity): 0.8788 ± 0.0939\n",
            "Specificity: 0.9673 ± 0.0081\n",
            "F1-score: 0.8936 ± 0.0592\n",
            "AUC-ROC: 0.9881 ± 0.0080\n",
            "AUPRC: 0.9763 ± 0.0162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LGBM**"
      ],
      "metadata": {
        "id": "Hiw1oed9NCVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.5, num_leaves=31, random_state=42)\n",
        "\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2YvT9E2ND-P",
        "outputId": "fe8fc7b6-0ea4-4ca6-e809-0e0dfe99ceb6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "[LightGBM] [Info] Number of positive: 218, number of negative: 218\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000276 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 131\n",
            "[LightGBM] [Info] Number of data points in the train set: 436, number of used features: 26\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "\n",
            "Confusion Matrix:\n",
            "[[53  2]\n",
            " [ 2 20]]\n",
            "Accuracy: 0.9481\n",
            "Precision: 0.9091\n",
            "Recall (Sensitivity): 0.9091\n",
            "Specificity: 0.9636\n",
            "F1-score: 0.9091\n",
            "AUC-ROC: 0.9851\n",
            "AUPRC: 0.9719\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 219, 1: 219})\n",
            "[LightGBM] [Info] Number of positive: 219, number of negative: 219\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000174 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 127\n",
            "[LightGBM] [Info] Number of data points in the train set: 438, number of used features: 26\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "\n",
            "Confusion Matrix:\n",
            "[[54  1]\n",
            " [ 2 20]]\n",
            "Accuracy: 0.9610\n",
            "Precision: 0.9524\n",
            "Recall (Sensitivity): 0.9091\n",
            "Specificity: 0.9818\n",
            "F1-score: 0.9302\n",
            "AUC-ROC: 0.9810\n",
            "AUPRC: 0.9596\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "[LightGBM] [Info] Number of positive: 218, number of negative: 218\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 132\n",
            "[LightGBM] [Info] Number of data points in the train set: 436, number of used features: 26\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "\n",
            "Confusion Matrix:\n",
            "[[51  4]\n",
            " [ 2 20]]\n",
            "Accuracy: 0.9221\n",
            "Precision: 0.8333\n",
            "Recall (Sensitivity): 0.9091\n",
            "Specificity: 0.9273\n",
            "F1-score: 0.8696\n",
            "AUC-ROC: 0.9860\n",
            "AUPRC: 0.9717\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 87})\n",
            "After SMOTE-Tomek:  Counter({0: 219, 1: 219})\n",
            "[LightGBM] [Info] Number of positive: 219, number of negative: 219\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 130\n",
            "[LightGBM] [Info] Number of data points in the train set: 438, number of used features: 26\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "\n",
            "Confusion Matrix:\n",
            "[[53  2]\n",
            " [ 0 21]]\n",
            "Accuracy: 0.9737\n",
            "Precision: 0.9130\n",
            "Recall (Sensitivity): 1.0000\n",
            "Specificity: 0.9636\n",
            "F1-score: 0.9545\n",
            "AUC-ROC: 0.9931\n",
            "AUPRC: 0.9818\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 87})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "[LightGBM] [Info] Number of positive: 218, number of negative: 218\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000223 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 128\n",
            "[LightGBM] [Info] Number of data points in the train set: 436, number of used features: 25\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "\n",
            "Confusion Matrix:\n",
            "[[53  2]\n",
            " [ 4 17]]\n",
            "Accuracy: 0.9211\n",
            "Precision: 0.8947\n",
            "Recall (Sensitivity): 0.8095\n",
            "Specificity: 0.9636\n",
            "F1-score: 0.8500\n",
            "AUC-ROC: 0.9714\n",
            "AUPRC: 0.9427\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.9452 ± 0.0234\n",
            "Precision: 0.9005 ± 0.0432\n",
            "Recall (Sensitivity): 0.9074 ± 0.0674\n",
            "Specificity: 0.9600 ± 0.0199\n",
            "F1-score: 0.9027 ± 0.0429\n",
            "AUC-ROC: 0.9833 ± 0.0079\n",
            "AUPRC: 0.9655 ± 0.0150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CB**"
      ],
      "metadata": {
        "id": "JuYEfm7mNwch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ET6PHNAcNyPU",
        "outputId": "ebc24c98-3707-4d33-e7c4-5d5141eb4811"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.3.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = CatBoostClassifier(\n",
        "      iterations=100,\n",
        "      learning_rate=0.1,\n",
        "      depth=3,\n",
        "      random_state=42,\n",
        "      verbose=0  # Suppress verbose output\n",
        "  )\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_onTWVDN81A",
        "outputId": "2f6f90de-6566-4a0d-df14-b291bde28e33"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({'Recurred': 1})\n",
            "After SMOTE-Tomek:  Counter({'Recurred': 1})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[53  2]\n",
            " [ 1 21]]\n",
            "Accuracy: 0.9610\n",
            "Precision: 0.9130\n",
            "Recall (Sensitivity): 0.9545\n",
            "Specificity: 0.9636\n",
            "F1-score: 0.9333\n",
            "AUC-ROC: 0.9876\n",
            "AUPRC: 0.9803\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({'Recurred': 1})\n",
            "After SMOTE-Tomek:  Counter({'Recurred': 1})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[54  1]\n",
            " [ 2 20]]\n",
            "Accuracy: 0.9610\n",
            "Precision: 0.9524\n",
            "Recall (Sensitivity): 0.9091\n",
            "Specificity: 0.9818\n",
            "F1-score: 0.9302\n",
            "AUC-ROC: 0.9769\n",
            "AUPRC: 0.9595\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({'Recurred': 1})\n",
            "After SMOTE-Tomek:  Counter({'Recurred': 1})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[53  2]\n",
            " [ 2 20]]\n",
            "Accuracy: 0.9481\n",
            "Precision: 0.9091\n",
            "Recall (Sensitivity): 0.9091\n",
            "Specificity: 0.9636\n",
            "F1-score: 0.9091\n",
            "AUC-ROC: 0.9909\n",
            "AUPRC: 0.9808\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({'Recurred': 1})\n",
            "After SMOTE-Tomek:  Counter({'Recurred': 1})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[54  1]\n",
            " [ 1 20]]\n",
            "Accuracy: 0.9737\n",
            "Precision: 0.9524\n",
            "Recall (Sensitivity): 0.9524\n",
            "Specificity: 0.9818\n",
            "F1-score: 0.9524\n",
            "AUC-ROC: 0.9965\n",
            "AUPRC: 0.9924\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({'Recurred': 1})\n",
            "After SMOTE-Tomek:  Counter({'Recurred': 1})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[52  3]\n",
            " [ 3 18]]\n",
            "Accuracy: 0.9211\n",
            "Precision: 0.8571\n",
            "Recall (Sensitivity): 0.8571\n",
            "Specificity: 0.9455\n",
            "F1-score: 0.8571\n",
            "AUC-ROC: 0.9784\n",
            "AUPRC: 0.9515\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.9530 ± 0.0200\n",
            "Precision: 0.9168 ± 0.0393\n",
            "Recall (Sensitivity): 0.9165 ± 0.0399\n",
            "Specificity: 0.9673 ± 0.0152\n",
            "F1-score: 0.9164 ± 0.0365\n",
            "AUC-ROC: 0.9861 ± 0.0084\n",
            "AUPRC: 0.9729 ± 0.0168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BNB**"
      ],
      "metadata": {
        "id": "3J1ZMuZ_OTiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = BernoulliNB()\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FF5rwqphOWsf",
        "outputId": "2170b95d-0173-4592-84f1-91789eaee4f0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[54  1]\n",
            " [ 4 18]]\n",
            "Accuracy: 0.9351\n",
            "Precision: 0.9474\n",
            "Recall (Sensitivity): 0.8182\n",
            "Specificity: 0.9818\n",
            "F1-score: 0.8780\n",
            "AUC-ROC: 0.9810\n",
            "AUPRC: 0.9600\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 219, 1: 219})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[50  5]\n",
            " [ 2 20]]\n",
            "Accuracy: 0.9091\n",
            "Precision: 0.8000\n",
            "Recall (Sensitivity): 0.9091\n",
            "Specificity: 0.9091\n",
            "F1-score: 0.8511\n",
            "AUC-ROC: 0.9711\n",
            "AUPRC: 0.9349\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[49  6]\n",
            " [ 1 21]]\n",
            "Accuracy: 0.9091\n",
            "Precision: 0.7778\n",
            "Recall (Sensitivity): 0.9545\n",
            "Specificity: 0.8909\n",
            "F1-score: 0.8571\n",
            "AUC-ROC: 0.9769\n",
            "AUPRC: 0.9574\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 87})\n",
            "After SMOTE-Tomek:  Counter({0: 219, 1: 219})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[50  5]\n",
            " [ 3 18]]\n",
            "Accuracy: 0.8947\n",
            "Precision: 0.7826\n",
            "Recall (Sensitivity): 0.8571\n",
            "Specificity: 0.9091\n",
            "F1-score: 0.8182\n",
            "AUC-ROC: 0.9835\n",
            "AUPRC: 0.9627\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 87})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[49  6]\n",
            " [ 4 17]]\n",
            "Accuracy: 0.8684\n",
            "Precision: 0.7391\n",
            "Recall (Sensitivity): 0.8095\n",
            "Specificity: 0.8909\n",
            "F1-score: 0.7727\n",
            "AUC-ROC: 0.9714\n",
            "AUPRC: 0.9390\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.9033 ± 0.0243\n",
            "Precision: 0.8094 ± 0.0803\n",
            "Recall (Sensitivity): 0.8697 ± 0.0616\n",
            "Specificity: 0.9164 ± 0.0377\n",
            "F1-score: 0.8354 ± 0.0411\n",
            "AUC-ROC: 0.9768 ± 0.0056\n",
            "AUPRC: 0.9508 ± 0.0129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNB**"
      ],
      "metadata": {
        "id": "Q7BlsqC3Pyok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = MinMaxScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = ComplementNB()\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvPqjYYvP0i8",
        "outputId": "03f1cb97-caa5-4c09-93da-3c6ed96219ad"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[55  0]\n",
            " [ 4 18]]\n",
            "Accuracy: 0.9481\n",
            "Precision: 1.0000\n",
            "Recall (Sensitivity): 0.8182\n",
            "Specificity: 1.0000\n",
            "F1-score: 0.9000\n",
            "AUC-ROC: 0.9876\n",
            "AUPRC: 0.9731\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 219, 1: 219})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[51  4]\n",
            " [ 2 20]]\n",
            "Accuracy: 0.9221\n",
            "Precision: 0.8333\n",
            "Recall (Sensitivity): 0.9091\n",
            "Specificity: 0.9273\n",
            "F1-score: 0.8696\n",
            "AUC-ROC: 0.9727\n",
            "AUPRC: 0.9456\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[49  6]\n",
            " [ 1 21]]\n",
            "Accuracy: 0.9091\n",
            "Precision: 0.7778\n",
            "Recall (Sensitivity): 0.9545\n",
            "Specificity: 0.8909\n",
            "F1-score: 0.8571\n",
            "AUC-ROC: 0.9810\n",
            "AUPRC: 0.9636\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 87})\n",
            "After SMOTE-Tomek:  Counter({0: 219, 1: 219})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[51  4]\n",
            " [ 3 18]]\n",
            "Accuracy: 0.9079\n",
            "Precision: 0.8182\n",
            "Recall (Sensitivity): 0.8571\n",
            "Specificity: 0.9273\n",
            "F1-score: 0.8372\n",
            "AUC-ROC: 0.9844\n",
            "AUPRC: 0.9646\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 87})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[50  5]\n",
            " [ 3 18]]\n",
            "Accuracy: 0.8947\n",
            "Precision: 0.7826\n",
            "Recall (Sensitivity): 0.8571\n",
            "Specificity: 0.9091\n",
            "F1-score: 0.8182\n",
            "AUC-ROC: 0.9775\n",
            "AUPRC: 0.9505\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.9164 ± 0.0202\n",
            "Precision: 0.8424 ± 0.0912\n",
            "Recall (Sensitivity): 0.8792 ± 0.0531\n",
            "Specificity: 0.9309 ± 0.0415\n",
            "F1-score: 0.8564 ± 0.0312\n",
            "AUC-ROC: 0.9806 ± 0.0058\n",
            "AUPRC: 0.9595 ± 0.0112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MNB**"
      ],
      "metadata": {
        "id": "uadWJ2gDQSTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = MinMaxScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = MultinomialNB()\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLAkCv-AQUHE",
        "outputId": "915f406d-5c99-4ced-d9bc-0cba897eda20"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[55  0]\n",
            " [ 4 18]]\n",
            "Accuracy: 0.9481\n",
            "Precision: 1.0000\n",
            "Recall (Sensitivity): 0.8182\n",
            "Specificity: 1.0000\n",
            "F1-score: 0.9000\n",
            "AUC-ROC: 0.9876\n",
            "AUPRC: 0.9731\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 219, 1: 219})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[51  4]\n",
            " [ 2 20]]\n",
            "Accuracy: 0.9221\n",
            "Precision: 0.8333\n",
            "Recall (Sensitivity): 0.9091\n",
            "Specificity: 0.9273\n",
            "F1-score: 0.8696\n",
            "AUC-ROC: 0.9727\n",
            "AUPRC: 0.9456\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[49  6]\n",
            " [ 1 21]]\n",
            "Accuracy: 0.9091\n",
            "Precision: 0.7778\n",
            "Recall (Sensitivity): 0.9545\n",
            "Specificity: 0.8909\n",
            "F1-score: 0.8571\n",
            "AUC-ROC: 0.9810\n",
            "AUPRC: 0.9636\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 87})\n",
            "After SMOTE-Tomek:  Counter({0: 219, 1: 219})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[51  4]\n",
            " [ 3 18]]\n",
            "Accuracy: 0.9079\n",
            "Precision: 0.8182\n",
            "Recall (Sensitivity): 0.8571\n",
            "Specificity: 0.9273\n",
            "F1-score: 0.8372\n",
            "AUC-ROC: 0.9844\n",
            "AUPRC: 0.9646\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 87})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[50  5]\n",
            " [ 3 18]]\n",
            "Accuracy: 0.8947\n",
            "Precision: 0.7826\n",
            "Recall (Sensitivity): 0.8571\n",
            "Specificity: 0.9091\n",
            "F1-score: 0.8182\n",
            "AUC-ROC: 0.9775\n",
            "AUPRC: 0.9505\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.9164 ± 0.0202\n",
            "Precision: 0.8424 ± 0.0912\n",
            "Recall (Sensitivity): 0.8792 ± 0.0531\n",
            "Specificity: 0.9309 ± 0.0415\n",
            "F1-score: 0.8564 ± 0.0312\n",
            "AUC-ROC: 0.9806 ± 0.0058\n",
            "AUPRC: 0.9595 ± 0.0112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HGB**"
      ],
      "metadata": {
        "id": "yi856i34QiHw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = HistGradientBoostingClassifier(\n",
        "        max_iter=100,\n",
        "        learning_rate=0.5,\n",
        "        max_depth=5,\n",
        "        random_state=42\n",
        "    )\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irZCS3cBQlOt",
        "outputId": "e748c362-4ed4-4af1-960f-dc3aebb1ea9c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[52  3]\n",
            " [ 3 19]]\n",
            "Accuracy: 0.9221\n",
            "Precision: 0.8636\n",
            "Recall (Sensitivity): 0.8636\n",
            "Specificity: 0.9455\n",
            "F1-score: 0.8636\n",
            "AUC-ROC: 0.9752\n",
            "AUPRC: 0.9618\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 219, 1: 219})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[54  1]\n",
            " [ 2 20]]\n",
            "Accuracy: 0.9610\n",
            "Precision: 0.9524\n",
            "Recall (Sensitivity): 0.9091\n",
            "Specificity: 0.9818\n",
            "F1-score: 0.9302\n",
            "AUC-ROC: 0.9868\n",
            "AUPRC: 0.9766\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[52  3]\n",
            " [ 1 21]]\n",
            "Accuracy: 0.9481\n",
            "Precision: 0.8750\n",
            "Recall (Sensitivity): 0.9545\n",
            "Specificity: 0.9455\n",
            "F1-score: 0.9130\n",
            "AUC-ROC: 0.9893\n",
            "AUPRC: 0.9790\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 87})\n",
            "After SMOTE-Tomek:  Counter({0: 219, 1: 219})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[52  3]\n",
            " [ 1 20]]\n",
            "Accuracy: 0.9474\n",
            "Precision: 0.8696\n",
            "Recall (Sensitivity): 0.9524\n",
            "Specificity: 0.9455\n",
            "F1-score: 0.9091\n",
            "AUC-ROC: 0.9913\n",
            "AUPRC: 0.9784\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 87})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[53  2]\n",
            " [ 4 17]]\n",
            "Accuracy: 0.9211\n",
            "Precision: 0.8947\n",
            "Recall (Sensitivity): 0.8095\n",
            "Specificity: 0.9636\n",
            "F1-score: 0.8500\n",
            "AUC-ROC: 0.9749\n",
            "AUPRC: 0.9478\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.9399 ± 0.0176\n",
            "Precision: 0.8911 ± 0.0362\n",
            "Recall (Sensitivity): 0.8978 ± 0.0618\n",
            "Specificity: 0.9564 ± 0.0163\n",
            "F1-score: 0.8932 ± 0.0345\n",
            "AUC-ROC: 0.9835 ± 0.0079\n",
            "AUPRC: 0.9687 ± 0.0137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NC**"
      ],
      "metadata": {
        "id": "26bRGv3cREX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import NearestCentroid\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = NearestCentroid()\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qm2NnfelRGgN",
        "outputId": "26906727-8c6e-48bb-dcd6-cd0515954b98"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[52  3]\n",
            " [ 5 17]]\n",
            "Accuracy: 0.8961\n",
            "Precision: 0.8500\n",
            "Recall (Sensitivity): 0.7727\n",
            "Specificity: 0.9455\n",
            "F1-score: 0.8095\n",
            "AUC-ROC: 0.9777\n",
            "AUPRC: 0.9528\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 219, 1: 219})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[50  5]\n",
            " [ 2 20]]\n",
            "Accuracy: 0.9091\n",
            "Precision: 0.8000\n",
            "Recall (Sensitivity): 0.9091\n",
            "Specificity: 0.9091\n",
            "F1-score: 0.8511\n",
            "AUC-ROC: 0.9698\n",
            "AUPRC: 0.9128\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 86})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[49  6]\n",
            " [ 1 21]]\n",
            "Accuracy: 0.9091\n",
            "Precision: 0.7778\n",
            "Recall (Sensitivity): 0.9545\n",
            "Specificity: 0.8909\n",
            "F1-score: 0.8571\n",
            "AUC-ROC: 0.9793\n",
            "AUPRC: 0.9611\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 87})\n",
            "After SMOTE-Tomek:  Counter({0: 219, 1: 219})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[50  5]\n",
            " [ 4 17]]\n",
            "Accuracy: 0.8816\n",
            "Precision: 0.7727\n",
            "Recall (Sensitivity): 0.8095\n",
            "Specificity: 0.9091\n",
            "F1-score: 0.7907\n",
            "AUC-ROC: 0.9818\n",
            "AUPRC: 0.9577\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({0: 220, 1: 87})\n",
            "After SMOTE-Tomek:  Counter({0: 218, 1: 218})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[48  7]\n",
            " [ 4 17]]\n",
            "Accuracy: 0.8553\n",
            "Precision: 0.7083\n",
            "Recall (Sensitivity): 0.8095\n",
            "Specificity: 0.8727\n",
            "F1-score: 0.7556\n",
            "AUC-ROC: 0.9714\n",
            "AUPRC: 0.9388\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.8902 ± 0.0226\n",
            "Precision: 0.7818 ± 0.0512\n",
            "Recall (Sensitivity): 0.8511 ± 0.0769\n",
            "Specificity: 0.9055 ± 0.0270\n",
            "F1-score: 0.8128 ± 0.0424\n",
            "AUC-ROC: 0.9760 ± 0.0052\n",
            "AUPRC: 0.9446 ± 0.0197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANN**"
      ],
      "metadata": {
        "id": "dAd2Et5ARgBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, average_precision_score, confusion_matrix\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target Series (0/1)\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# CV Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split\n",
        "    X_train_raw, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train_raw, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", dict(pd.Series(y_train_raw).value_counts()))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train_raw, y_train_raw)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", dict(pd.Series(y_train_res).value_counts()))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Build ANN\n",
        "    # =========================\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "        Dropout(0.3),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=10,\n",
        "        restore_best_weights=True,\n",
        "        verbose=0\n",
        "    )\n",
        "    reduce_lr = ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        min_lr=1e-6,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        X_train_scaled, y_train_res,\n",
        "        epochs=300,\n",
        "        batch_size=32,\n",
        "        validation_split=0.2,\n",
        "        callbacks=[early_stop, reduce_lr],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_proba = model.predict(X_test_scaled).ravel()\n",
        "    y_pred = (y_proba >= 0.8).astype(int)\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# CV Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary (ANN) ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22wemxUKRhkj",
        "outputId": "2a9cf977-2d9e-4fcc-a719-77b55e27f9c5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: {0: np.int64(220), 1: np.int64(86)}\n",
            "After SMOTE-Tomek:  {0: np.int64(218), 1: np.int64(218)}\n",
            "\n",
            "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[55  0]\n",
            " [ 2 20]]\n",
            "Accuracy: 0.9740\n",
            "Precision: 1.0000\n",
            "Recall (Sensitivity): 0.9091\n",
            "Specificity: 1.0000\n",
            "F1-score: 0.9524\n",
            "AUC-ROC: 0.9884\n",
            "AUPRC: 0.9811\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: {0: np.int64(220), 1: np.int64(86)}\n",
            "After SMOTE-Tomek:  {0: np.int64(219), 1: np.int64(219)}\n",
            "\n",
            "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[54  1]\n",
            " [ 2 20]]\n",
            "Accuracy: 0.9610\n",
            "Precision: 0.9524\n",
            "Recall (Sensitivity): 0.9091\n",
            "Specificity: 0.9818\n",
            "F1-score: 0.9302\n",
            "AUC-ROC: 0.9777\n",
            "AUPRC: 0.9684\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: {0: np.int64(220), 1: np.int64(86)}\n",
            "After SMOTE-Tomek:  {0: np.int64(218), 1: np.int64(218)}\n",
            "\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7def439aa660> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 180ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7def439aa660> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[54  1]\n",
            " [ 2 20]]\n",
            "Accuracy: 0.9610\n",
            "Precision: 0.9524\n",
            "Recall (Sensitivity): 0.9091\n",
            "Specificity: 0.9818\n",
            "F1-score: 0.9302\n",
            "AUC-ROC: 0.9835\n",
            "AUPRC: 0.9725\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: {0: np.int64(220), 1: np.int64(87)}\n",
            "After SMOTE-Tomek:  {0: np.int64(219), 1: np.int64(219)}\n",
            "\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[53  2]\n",
            " [ 1 20]]\n",
            "Accuracy: 0.9605\n",
            "Precision: 0.9091\n",
            "Recall (Sensitivity): 0.9524\n",
            "Specificity: 0.9636\n",
            "F1-score: 0.9302\n",
            "AUC-ROC: 0.9844\n",
            "AUPRC: 0.9712\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: {0: np.int64(220), 1: np.int64(87)}\n",
            "After SMOTE-Tomek:  {0: np.int64(218), 1: np.int64(218)}\n",
            "\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 58: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[54  1]\n",
            " [ 6 15]]\n",
            "Accuracy: 0.9079\n",
            "Precision: 0.9375\n",
            "Recall (Sensitivity): 0.7143\n",
            "Specificity: 0.9818\n",
            "F1-score: 0.8108\n",
            "AUC-ROC: 0.9801\n",
            "AUPRC: 0.9566\n",
            "\n",
            "=========== 5-Fold CV Summary (ANN) ===========\n",
            "\n",
            "Accuracy: 0.9529 ± 0.0258\n",
            "Precision: 0.9503 ± 0.0329\n",
            "Recall (Sensitivity): 0.8788 ± 0.0939\n",
            "Specificity: 0.9818 ± 0.0129\n",
            "F1-score: 0.9108 ± 0.0567\n",
            "AUC-ROC: 0.9828 ± 0.0041\n",
            "AUPRC: 0.9699 ± 0.0088\n"
          ]
        }
      ]
    }
  ]
}