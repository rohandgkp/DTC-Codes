{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FCohde18Scti"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/content/cleaned_dataset_Thyroid1.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_dkvFQIS4ei",
        "outputId": "823731b7-a586-42e8-dd80-3de92106a360"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3771 entries, 0 to 3770\n",
            "Data columns (total 26 columns):\n",
            " #   Column                     Non-Null Count  Dtype  \n",
            "---  ------                     --------------  -----  \n",
            " 0   age                        3771 non-null   float64\n",
            " 1   sex                        3771 non-null   float64\n",
            " 2   on thyroxine               3771 non-null   int64  \n",
            " 3   query on thyroxine         3771 non-null   int64  \n",
            " 4   on antithyroid medication  3771 non-null   int64  \n",
            " 5   sick                       3771 non-null   int64  \n",
            " 6   pregnant                   3771 non-null   int64  \n",
            " 7   thyroid surgery            3771 non-null   int64  \n",
            " 8   I131 treatment             3771 non-null   int64  \n",
            " 9   query hypothyroid          3771 non-null   int64  \n",
            " 10  query hyperthyroid         3771 non-null   int64  \n",
            " 11  lithium                    3771 non-null   int64  \n",
            " 12  goitre                     3771 non-null   int64  \n",
            " 13  tumor                      3771 non-null   int64  \n",
            " 14  hypopituitary              3771 non-null   int64  \n",
            " 15  psych                      3771 non-null   int64  \n",
            " 16  TSH measured               3771 non-null   int64  \n",
            " 17  TSH                        3771 non-null   float64\n",
            " 18  T3 measured                3771 non-null   int64  \n",
            " 19  TT4 measured               3771 non-null   int64  \n",
            " 20  TT4                        3771 non-null   float64\n",
            " 21  T4U measured               3771 non-null   float64\n",
            " 22  T4U                        3771 non-null   float64\n",
            " 23  FTI measured               3771 non-null   int64  \n",
            " 24  FTI                        3771 non-null   float64\n",
            " 25  binaryClass                3771 non-null   int64  \n",
            "dtypes: float64(7), int64(19)\n",
            "memory usage: 766.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 899
        },
        "id": "kdMt-ud1S7_3",
        "outputId": "73015f60-4956-4ec0-cbe2-5ba593998850"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                          0\n",
              "sex                          0\n",
              "on thyroxine                 0\n",
              "query on thyroxine           0\n",
              "on antithyroid medication    0\n",
              "sick                         0\n",
              "pregnant                     0\n",
              "thyroid surgery              0\n",
              "I131 treatment               0\n",
              "query hypothyroid            0\n",
              "query hyperthyroid           0\n",
              "lithium                      0\n",
              "goitre                       0\n",
              "tumor                        0\n",
              "hypopituitary                0\n",
              "psych                        0\n",
              "TSH measured                 0\n",
              "TSH                          0\n",
              "T3 measured                  0\n",
              "TT4 measured                 0\n",
              "TT4                          0\n",
              "T4U measured                 0\n",
              "T4U                          0\n",
              "FTI measured                 0\n",
              "FTI                          0\n",
              "binaryClass                  0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sex</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>on thyroxine</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>query on thyroxine</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>on antithyroid medication</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sick</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pregnant</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>thyroid surgery</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I131 treatment</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>query hypothyroid</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>query hyperthyroid</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lithium</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>goitre</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tumor</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hypopituitary</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>psych</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TSH measured</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TSH</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T3 measured</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TT4 measured</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TT4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T4U measured</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T4U</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FTI measured</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FTI</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>binaryClass</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Features and target\n",
        "X = data.drop(columns=[\"binaryClass\"])\n",
        "y = data[\"binaryClass\"]\n"
      ],
      "metadata": {
        "id": "2d0r07gxS-MS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHjm8ImcTFMP",
        "outputId": "cd02670d-9667-4bb7-b92d-b48541f67f48"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3771 entries, 0 to 3770\n",
            "Data columns (total 25 columns):\n",
            " #   Column                     Non-Null Count  Dtype  \n",
            "---  ------                     --------------  -----  \n",
            " 0   age                        3771 non-null   float64\n",
            " 1   sex                        3771 non-null   float64\n",
            " 2   on thyroxine               3771 non-null   int64  \n",
            " 3   query on thyroxine         3771 non-null   int64  \n",
            " 4   on antithyroid medication  3771 non-null   int64  \n",
            " 5   sick                       3771 non-null   int64  \n",
            " 6   pregnant                   3771 non-null   int64  \n",
            " 7   thyroid surgery            3771 non-null   int64  \n",
            " 8   I131 treatment             3771 non-null   int64  \n",
            " 9   query hypothyroid          3771 non-null   int64  \n",
            " 10  query hyperthyroid         3771 non-null   int64  \n",
            " 11  lithium                    3771 non-null   int64  \n",
            " 12  goitre                     3771 non-null   int64  \n",
            " 13  tumor                      3771 non-null   int64  \n",
            " 14  hypopituitary              3771 non-null   int64  \n",
            " 15  psych                      3771 non-null   int64  \n",
            " 16  TSH measured               3771 non-null   int64  \n",
            " 17  TSH                        3771 non-null   float64\n",
            " 18  T3 measured                3771 non-null   int64  \n",
            " 19  TT4 measured               3771 non-null   int64  \n",
            " 20  TT4                        3771 non-null   float64\n",
            " 21  T4U measured               3771 non-null   float64\n",
            " 22  T4U                        3771 non-null   float64\n",
            " 23  FTI measured               3771 non-null   int64  \n",
            " 24  FTI                        3771 non-null   float64\n",
            "dtypes: float64(7), int64(18)\n",
            "memory usage: 736.7 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LR"
      ],
      "metadata": {
        "id": "Vx5jFIJjTKzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = LogisticRegression(\n",
        "        max_iter=1000,\n",
        "        random_state=42,\n",
        "        class_weight='balanced'\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOVhaCvNTJvC",
        "outputId": "cf40d2ee-3059-4598-edff-e6000865006a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 232})\n",
            "After SMOTE-Tomek:  Counter({0: 2775, 1: 2775})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[682  14]\n",
            " [  4  55]]\n",
            "Accuracy: 0.9762\n",
            "Precision: 0.7971\n",
            "Recall (Sensitivity): 0.9322\n",
            "Specificity: 0.9799\n",
            "F1-score: 0.8594\n",
            "AUC-ROC: 0.9936\n",
            "AUPRC: 0.9519\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2778, 1: 2778})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[684  12]\n",
            " [ 10  48]]\n",
            "Accuracy: 0.9708\n",
            "Precision: 0.8000\n",
            "Recall (Sensitivity): 0.8276\n",
            "Specificity: 0.9828\n",
            "F1-score: 0.8136\n",
            "AUC-ROC: 0.9602\n",
            "AUPRC: 0.8281\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2777, 1: 2777})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[683  13]\n",
            " [  9  49]]\n",
            "Accuracy: 0.9708\n",
            "Precision: 0.7903\n",
            "Recall (Sensitivity): 0.8448\n",
            "Specificity: 0.9813\n",
            "F1-score: 0.8167\n",
            "AUC-ROC: 0.9516\n",
            "AUPRC: 0.8798\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[681  15]\n",
            " [ 10  48]]\n",
            "Accuracy: 0.9668\n",
            "Precision: 0.7619\n",
            "Recall (Sensitivity): 0.8276\n",
            "Specificity: 0.9784\n",
            "F1-score: 0.7934\n",
            "AUC-ROC: 0.9573\n",
            "AUPRC: 0.8555\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[680  16]\n",
            " [ 11  47]]\n",
            "Accuracy: 0.9642\n",
            "Precision: 0.7460\n",
            "Recall (Sensitivity): 0.8103\n",
            "Specificity: 0.9770\n",
            "F1-score: 0.7769\n",
            "AUC-ROC: 0.9538\n",
            "AUPRC: 0.7785\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.9698 ± 0.0045\n",
            "Precision: 0.7791 ± 0.0239\n",
            "Recall (Sensitivity): 0.8485 ± 0.0483\n",
            "Specificity: 0.9799 ± 0.0023\n",
            "F1-score: 0.8120 ± 0.0310\n",
            "AUC-ROC: 0.9633 ± 0.0172\n",
            "AUPRC: 0.8587 ± 0.0643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RF"
      ],
      "metadata": {
        "id": "4T2RDKVwTWVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = RandomForestClassifier(n_estimators=100, max_depth=6, random_state=42)\n",
        "\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pMDG-zPTXBU",
        "outputId": "5bad6a69-e06d-45b0-eaa3-a510fb43e30b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 232})\n",
            "After SMOTE-Tomek:  Counter({0: 2775, 1: 2775})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[691   5]\n",
            " [  0  59]]\n",
            "Accuracy: 0.9934\n",
            "Precision: 0.9219\n",
            "Recall (Sensitivity): 1.0000\n",
            "Specificity: 0.9928\n",
            "F1-score: 0.9593\n",
            "AUC-ROC: 0.9999\n",
            "AUPRC: 0.9988\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2778, 1: 2778})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[693   3]\n",
            " [  0  58]]\n",
            "Accuracy: 0.9960\n",
            "Precision: 0.9508\n",
            "Recall (Sensitivity): 1.0000\n",
            "Specificity: 0.9957\n",
            "F1-score: 0.9748\n",
            "AUC-ROC: 1.0000\n",
            "AUPRC: 1.0000\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2777, 1: 2777})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[689   7]\n",
            " [  0  58]]\n",
            "Accuracy: 0.9907\n",
            "Precision: 0.8923\n",
            "Recall (Sensitivity): 1.0000\n",
            "Specificity: 0.9899\n",
            "F1-score: 0.9431\n",
            "AUC-ROC: 0.9973\n",
            "AUPRC: 0.9528\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[688   8]\n",
            " [  2  56]]\n",
            "Accuracy: 0.9867\n",
            "Precision: 0.8750\n",
            "Recall (Sensitivity): 0.9655\n",
            "Specificity: 0.9885\n",
            "F1-score: 0.9180\n",
            "AUC-ROC: 0.9975\n",
            "AUPRC: 0.9846\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[692   4]\n",
            " [  0  58]]\n",
            "Accuracy: 0.9947\n",
            "Precision: 0.9355\n",
            "Recall (Sensitivity): 1.0000\n",
            "Specificity: 0.9943\n",
            "F1-score: 0.9667\n",
            "AUC-ROC: 0.9987\n",
            "AUPRC: 0.9784\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.9923 ± 0.0037\n",
            "Precision: 0.9151 ± 0.0311\n",
            "Recall (Sensitivity): 0.9931 ± 0.0154\n",
            "Specificity: 0.9922 ± 0.0030\n",
            "F1-score: 0.9524 ± 0.0225\n",
            "AUC-ROC: 0.9987 ± 0.0013\n",
            "AUPRC: 0.9829 ± 0.0192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN"
      ],
      "metadata": {
        "id": "fGj-iRPnTfra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ljjekYWTgm1",
        "outputId": "ec94bfb0-6ecd-4fd4-8491-2ac3e937b5d5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 232})\n",
            "After SMOTE-Tomek:  Counter({0: 2775, 1: 2775})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[613  83]\n",
            " [ 25  34]]\n",
            "Accuracy: 0.8570\n",
            "Precision: 0.2906\n",
            "Recall (Sensitivity): 0.5763\n",
            "Specificity: 0.8807\n",
            "F1-score: 0.3864\n",
            "AUC-ROC: 0.8155\n",
            "AUPRC: 0.3659\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2778, 1: 2778})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[609  87]\n",
            " [ 29  29]]\n",
            "Accuracy: 0.8462\n",
            "Precision: 0.2500\n",
            "Recall (Sensitivity): 0.5000\n",
            "Specificity: 0.8750\n",
            "F1-score: 0.3333\n",
            "AUC-ROC: 0.7700\n",
            "AUPRC: 0.2721\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2777, 1: 2777})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[616  80]\n",
            " [ 33  25]]\n",
            "Accuracy: 0.8501\n",
            "Precision: 0.2381\n",
            "Recall (Sensitivity): 0.4310\n",
            "Specificity: 0.8851\n",
            "F1-score: 0.3067\n",
            "AUC-ROC: 0.7511\n",
            "AUPRC: 0.2993\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[631  65]\n",
            " [ 26  32]]\n",
            "Accuracy: 0.8793\n",
            "Precision: 0.3299\n",
            "Recall (Sensitivity): 0.5517\n",
            "Specificity: 0.9066\n",
            "F1-score: 0.4129\n",
            "AUC-ROC: 0.8133\n",
            "AUPRC: 0.4015\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[622  74]\n",
            " [ 35  23]]\n",
            "Accuracy: 0.8554\n",
            "Precision: 0.2371\n",
            "Recall (Sensitivity): 0.3966\n",
            "Specificity: 0.8937\n",
            "F1-score: 0.2968\n",
            "AUC-ROC: 0.6956\n",
            "AUPRC: 0.2331\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.8576 ± 0.0129\n",
            "Precision: 0.2691 ± 0.0403\n",
            "Recall (Sensitivity): 0.4911 ± 0.0767\n",
            "Specificity: 0.8882 ± 0.0123\n",
            "F1-score: 0.3472 ± 0.0506\n",
            "AUC-ROC: 0.7691 ± 0.0496\n",
            "AUPRC: 0.3144 ± 0.0687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GNB"
      ],
      "metadata": {
        "id": "QVMOzb3eTz9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = GaussianNB()\n",
        "\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvM3YsHGT08g",
        "outputId": "4da88d9a-435f-469f-90a7-f48fa489b4a0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 232})\n",
            "After SMOTE-Tomek:  Counter({0: 2775, 1: 2775})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[275 421]\n",
            " [  4  55]]\n",
            "Accuracy: 0.4371\n",
            "Precision: 0.1155\n",
            "Recall (Sensitivity): 0.9322\n",
            "Specificity: 0.3951\n",
            "F1-score: 0.2056\n",
            "AUC-ROC: 0.6763\n",
            "AUPRC: 0.1182\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2778, 1: 2778})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[276 420]\n",
            " [  9  49]]\n",
            "Accuracy: 0.4310\n",
            "Precision: 0.1045\n",
            "Recall (Sensitivity): 0.8448\n",
            "Specificity: 0.3966\n",
            "F1-score: 0.1860\n",
            "AUC-ROC: 0.6259\n",
            "AUPRC: 0.1020\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2777, 1: 2777})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[262 434]\n",
            " [ 11  47]]\n",
            "Accuracy: 0.4098\n",
            "Precision: 0.0977\n",
            "Recall (Sensitivity): 0.8103\n",
            "Specificity: 0.3764\n",
            "F1-score: 0.1744\n",
            "AUC-ROC: 0.6135\n",
            "AUPRC: 0.0999\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[300 396]\n",
            " [ 11  47]]\n",
            "Accuracy: 0.4602\n",
            "Precision: 0.1061\n",
            "Recall (Sensitivity): 0.8103\n",
            "Specificity: 0.4310\n",
            "F1-score: 0.1876\n",
            "AUC-ROC: 0.6369\n",
            "AUPRC: 0.1048\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[259 437]\n",
            " [ 12  46]]\n",
            "Accuracy: 0.4045\n",
            "Precision: 0.0952\n",
            "Recall (Sensitivity): 0.7931\n",
            "Specificity: 0.3721\n",
            "F1-score: 0.1701\n",
            "AUC-ROC: 0.5755\n",
            "AUPRC: 0.0912\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.4285 ± 0.0224\n",
            "Precision: 0.1038 ± 0.0080\n",
            "Recall (Sensitivity): 0.8382 ± 0.0558\n",
            "Specificity: 0.3943 ± 0.0233\n",
            "F1-score: 0.1847 ± 0.0139\n",
            "AUC-ROC: 0.6256 ± 0.0366\n",
            "AUPRC: 0.1032 ± 0.0098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP"
      ],
      "metadata": {
        "id": "NjjMgl4-VaGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = MLPClassifier(hidden_layer_sizes=(150, 100, 50), max_iter=1000, random_state=42)\n",
        "\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UWtBPlgVbCN",
        "outputId": "e076ba76-0619-4e9c-c6a5-f9354177ef2a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 232})\n",
            "After SMOTE-Tomek:  Counter({0: 2775, 1: 2775})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[690   6]\n",
            " [  9  50]]\n",
            "Accuracy: 0.9801\n",
            "Precision: 0.8929\n",
            "Recall (Sensitivity): 0.8475\n",
            "Specificity: 0.9914\n",
            "F1-score: 0.8696\n",
            "AUC-ROC: 0.9887\n",
            "AUPRC: 0.9443\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2778, 1: 2778})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[693   3]\n",
            " [ 13  45]]\n",
            "Accuracy: 0.9788\n",
            "Precision: 0.9375\n",
            "Recall (Sensitivity): 0.7759\n",
            "Specificity: 0.9957\n",
            "F1-score: 0.8491\n",
            "AUC-ROC: 0.9642\n",
            "AUPRC: 0.8752\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2777, 1: 2777})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[682  14]\n",
            " [  6  52]]\n",
            "Accuracy: 0.9735\n",
            "Precision: 0.7879\n",
            "Recall (Sensitivity): 0.8966\n",
            "Specificity: 0.9799\n",
            "F1-score: 0.8387\n",
            "AUC-ROC: 0.9594\n",
            "AUPRC: 0.9129\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[691   5]\n",
            " [  9  49]]\n",
            "Accuracy: 0.9814\n",
            "Precision: 0.9074\n",
            "Recall (Sensitivity): 0.8448\n",
            "Specificity: 0.9928\n",
            "F1-score: 0.8750\n",
            "AUC-ROC: 0.9681\n",
            "AUPRC: 0.8875\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[692   4]\n",
            " [ 17  41]]\n",
            "Accuracy: 0.9721\n",
            "Precision: 0.9111\n",
            "Recall (Sensitivity): 0.7069\n",
            "Specificity: 0.9943\n",
            "F1-score: 0.7961\n",
            "AUC-ROC: 0.9274\n",
            "AUPRC: 0.8054\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.9772 ± 0.0041\n",
            "Precision: 0.8874 ± 0.0579\n",
            "Recall (Sensitivity): 0.8143 ± 0.0738\n",
            "Specificity: 0.9908 ± 0.0063\n",
            "F1-score: 0.8457 ± 0.0314\n",
            "AUC-ROC: 0.9616 ± 0.0221\n",
            "AUPRC: 0.8850 ± 0.0518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGB"
      ],
      "metadata": {
        "id": "Qc9rWf2SVswo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pEm2iJ8VtkL",
        "outputId": "9c4989c0-27c1-4c47-e951-0e366ffa0bdf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 232})\n",
            "After SMOTE-Tomek:  Counter({0: 2775, 1: 2775})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[694   2]\n",
            " [  0  59]]\n",
            "Accuracy: 0.9974\n",
            "Precision: 0.9672\n",
            "Recall (Sensitivity): 1.0000\n",
            "Specificity: 0.9971\n",
            "F1-score: 0.9833\n",
            "AUC-ROC: 1.0000\n",
            "AUPRC: 1.0000\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2778, 1: 2778})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[696   0]\n",
            " [  0  58]]\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall (Sensitivity): 1.0000\n",
            "Specificity: 1.0000\n",
            "F1-score: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "AUPRC: 1.0000\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2777, 1: 2777})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[692   4]\n",
            " [  1  57]]\n",
            "Accuracy: 0.9934\n",
            "Precision: 0.9344\n",
            "Recall (Sensitivity): 0.9828\n",
            "Specificity: 0.9943\n",
            "F1-score: 0.9580\n",
            "AUC-ROC: 0.9981\n",
            "AUPRC: 0.9480\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[696   0]\n",
            " [  2  56]]\n",
            "Accuracy: 0.9973\n",
            "Precision: 1.0000\n",
            "Recall (Sensitivity): 0.9655\n",
            "Specificity: 1.0000\n",
            "F1-score: 0.9825\n",
            "AUC-ROC: 0.9904\n",
            "AUPRC: 0.9743\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[694   2]\n",
            " [  2  56]]\n",
            "Accuracy: 0.9947\n",
            "Precision: 0.9655\n",
            "Recall (Sensitivity): 0.9655\n",
            "Specificity: 0.9971\n",
            "F1-score: 0.9655\n",
            "AUC-ROC: 0.9972\n",
            "AUPRC: 0.9190\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.9966 ± 0.0026\n",
            "Precision: 0.9734 ± 0.0275\n",
            "Recall (Sensitivity): 0.9828 ± 0.0172\n",
            "Specificity: 0.9977 ± 0.0024\n",
            "F1-score: 0.9779 ± 0.0165\n",
            "AUC-ROC: 0.9971 ± 0.0039\n",
            "AUPRC: 0.9682 ± 0.0350\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ADB"
      ],
      "metadata": {
        "id": "MxG-t3i-V0kA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojWRi0LYV1ar",
        "outputId": "9092d715-1f0b-4ec6-ed17-79a79df4de52"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 232})\n",
            "After SMOTE-Tomek:  Counter({0: 2775, 1: 2775})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[692   4]\n",
            " [  0  59]]\n",
            "Accuracy: 0.9947\n",
            "Precision: 0.9365\n",
            "Recall (Sensitivity): 1.0000\n",
            "Specificity: 0.9943\n",
            "F1-score: 0.9672\n",
            "AUC-ROC: 1.0000\n",
            "AUPRC: 1.0000\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2778, 1: 2778})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[695   1]\n",
            " [  1  57]]\n",
            "Accuracy: 0.9973\n",
            "Precision: 0.9828\n",
            "Recall (Sensitivity): 0.9828\n",
            "Specificity: 0.9986\n",
            "F1-score: 0.9828\n",
            "AUC-ROC: 0.9999\n",
            "AUPRC: 0.9991\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2777, 1: 2777})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[689   7]\n",
            " [  0  58]]\n",
            "Accuracy: 0.9907\n",
            "Precision: 0.8923\n",
            "Recall (Sensitivity): 1.0000\n",
            "Specificity: 0.9899\n",
            "F1-score: 0.9431\n",
            "AUC-ROC: 0.9969\n",
            "AUPRC: 0.9429\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[688   8]\n",
            " [  3  55]]\n",
            "Accuracy: 0.9854\n",
            "Precision: 0.8730\n",
            "Recall (Sensitivity): 0.9483\n",
            "Specificity: 0.9885\n",
            "F1-score: 0.9091\n",
            "AUC-ROC: 0.9911\n",
            "AUPRC: 0.9705\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[692   4]\n",
            " [  0  58]]\n",
            "Accuracy: 0.9947\n",
            "Precision: 0.9355\n",
            "Recall (Sensitivity): 1.0000\n",
            "Specificity: 0.9943\n",
            "F1-score: 0.9667\n",
            "AUC-ROC: 0.9981\n",
            "AUPRC: 0.9600\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.9926 ± 0.0047\n",
            "Precision: 0.9240 ± 0.0429\n",
            "Recall (Sensitivity): 0.9862 ± 0.0225\n",
            "Specificity: 0.9931 ± 0.0040\n",
            "F1-score: 0.9538 ± 0.0287\n",
            "AUC-ROC: 0.9972 ± 0.0037\n",
            "AUPRC: 0.9745 ± 0.0249\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GBC"
      ],
      "metadata": {
        "id": "fODThpvHV8aR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = GradientBoostingClassifier(n_estimators=50, learning_rate=0.001, max_depth=3, random_state=42)\n",
        "\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wXGcxuqV9GH",
        "outputId": "31021690-e092-409e-a372-80bcc9313117"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 232})\n",
            "After SMOTE-Tomek:  Counter({0: 2775, 1: 2775})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[693   3]\n",
            " [  0  59]]\n",
            "Accuracy: 0.9960\n",
            "Precision: 0.9516\n",
            "Recall (Sensitivity): 1.0000\n",
            "Specificity: 0.9957\n",
            "F1-score: 0.9752\n",
            "AUC-ROC: 0.9993\n",
            "AUPRC: 0.9833\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2778, 1: 2778})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[694   2]\n",
            " [  0  58]]\n",
            "Accuracy: 0.9973\n",
            "Precision: 0.9667\n",
            "Recall (Sensitivity): 1.0000\n",
            "Specificity: 0.9971\n",
            "F1-score: 0.9831\n",
            "AUC-ROC: 1.0000\n",
            "AUPRC: 1.0000\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2777, 1: 2777})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[684  12]\n",
            " [  0  58]]\n",
            "Accuracy: 0.9841\n",
            "Precision: 0.8286\n",
            "Recall (Sensitivity): 1.0000\n",
            "Specificity: 0.9828\n",
            "F1-score: 0.9062\n",
            "AUC-ROC: 0.9958\n",
            "AUPRC: 0.9095\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[690   6]\n",
            " [  3  55]]\n",
            "Accuracy: 0.9881\n",
            "Precision: 0.9016\n",
            "Recall (Sensitivity): 0.9483\n",
            "Specificity: 0.9914\n",
            "F1-score: 0.9244\n",
            "AUC-ROC: 0.9764\n",
            "AUPRC: 0.8557\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[692   4]\n",
            " [  0  58]]\n",
            "Accuracy: 0.9947\n",
            "Precision: 0.9355\n",
            "Recall (Sensitivity): 1.0000\n",
            "Specificity: 0.9943\n",
            "F1-score: 0.9667\n",
            "AUC-ROC: 0.9973\n",
            "AUPRC: 0.9388\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.9920 ± 0.0057\n",
            "Precision: 0.9168 ± 0.0549\n",
            "Recall (Sensitivity): 0.9897 ± 0.0231\n",
            "Specificity: 0.9922 ± 0.0057\n",
            "F1-score: 0.9511 ± 0.0338\n",
            "AUC-ROC: 0.9938 ± 0.0098\n",
            "AUPRC: 0.9375 ± 0.0581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ETC"
      ],
      "metadata": {
        "id": "fy4zN-SeWDSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = ExtraTreesClassifier(\n",
        "        n_estimators=500,\n",
        "        max_depth=None,\n",
        "        criterion=\"entropy\",\n",
        "        min_samples_split=2,\n",
        "        min_samples_leaf=1,\n",
        "        max_features=None,\n",
        "        class_weight=\"balanced\",\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAUn52lsWD7H",
        "outputId": "8ab7947a-1858-435e-8329-138ea38bee59"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 232})\n",
            "After SMOTE-Tomek:  Counter({0: 2775, 1: 2775})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[692   4]\n",
            " [  0  59]]\n",
            "Accuracy: 0.9947\n",
            "Precision: 0.9365\n",
            "Recall (Sensitivity): 1.0000\n",
            "Specificity: 0.9943\n",
            "F1-score: 0.9672\n",
            "AUC-ROC: 0.9999\n",
            "AUPRC: 0.9983\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2778, 1: 2778})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[694   2]\n",
            " [  2  56]]\n",
            "Accuracy: 0.9947\n",
            "Precision: 0.9655\n",
            "Recall (Sensitivity): 0.9655\n",
            "Specificity: 0.9971\n",
            "F1-score: 0.9655\n",
            "AUC-ROC: 0.9998\n",
            "AUPRC: 0.9979\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2777, 1: 2777})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[690   6]\n",
            " [  0  58]]\n",
            "Accuracy: 0.9920\n",
            "Precision: 0.9062\n",
            "Recall (Sensitivity): 1.0000\n",
            "Specificity: 0.9914\n",
            "F1-score: 0.9508\n",
            "AUC-ROC: 0.9995\n",
            "AUPRC: 0.9934\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[695   1]\n",
            " [  2  56]]\n",
            "Accuracy: 0.9960\n",
            "Precision: 0.9825\n",
            "Recall (Sensitivity): 0.9655\n",
            "Specificity: 0.9986\n",
            "F1-score: 0.9739\n",
            "AUC-ROC: 0.9995\n",
            "AUPRC: 0.9949\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[693   3]\n",
            " [  0  58]]\n",
            "Accuracy: 0.9960\n",
            "Precision: 0.9508\n",
            "Recall (Sensitivity): 1.0000\n",
            "Specificity: 0.9957\n",
            "F1-score: 0.9748\n",
            "AUC-ROC: 0.9989\n",
            "AUPRC: 0.9838\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.9947 ± 0.0016\n",
            "Precision: 0.9483 ± 0.0291\n",
            "Recall (Sensitivity): 0.9862 ± 0.0189\n",
            "Specificity: 0.9954 ± 0.0028\n",
            "F1-score: 0.9665 ± 0.0096\n",
            "AUC-ROC: 0.9995 ± 0.0004\n",
            "AUPRC: 0.9937 ± 0.0059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = X_train_res\n",
        "    X_test_scaled = X_test\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = ExtraTreesClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=None,\n",
        "        min_samples_split=10,\n",
        "        min_samples_leaf=3,\n",
        "        max_features=\"sqrt\",\n",
        "        class_weight=\"balanced\",\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJmmCX9eWKu_",
        "outputId": "009ae923-b715-4cf8-e88a-4b0b6fdd3ea5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 232})\n",
            "After SMOTE-Tomek:  Counter({0: 2775, 1: 2775})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[677  19]\n",
            " [  9  50]]\n",
            "Accuracy: 0.9629\n",
            "Precision: 0.7246\n",
            "Recall (Sensitivity): 0.8475\n",
            "Specificity: 0.9727\n",
            "F1-score: 0.7812\n",
            "AUC-ROC: 0.9854\n",
            "AUPRC: 0.9102\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2778, 1: 2778})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[684  12]\n",
            " [ 10  48]]\n",
            "Accuracy: 0.9708\n",
            "Precision: 0.8000\n",
            "Recall (Sensitivity): 0.8276\n",
            "Specificity: 0.9828\n",
            "F1-score: 0.8136\n",
            "AUC-ROC: 0.9838\n",
            "AUPRC: 0.8783\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2777, 1: 2777})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[681  15]\n",
            " [ 10  48]]\n",
            "Accuracy: 0.9668\n",
            "Precision: 0.7619\n",
            "Recall (Sensitivity): 0.8276\n",
            "Specificity: 0.9784\n",
            "F1-score: 0.7934\n",
            "AUC-ROC: 0.9859\n",
            "AUPRC: 0.8905\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[687   9]\n",
            " [ 11  47]]\n",
            "Accuracy: 0.9735\n",
            "Precision: 0.8393\n",
            "Recall (Sensitivity): 0.8103\n",
            "Specificity: 0.9871\n",
            "F1-score: 0.8246\n",
            "AUC-ROC: 0.9875\n",
            "AUPRC: 0.9216\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[677  19]\n",
            " [ 10  48]]\n",
            "Accuracy: 0.9615\n",
            "Precision: 0.7164\n",
            "Recall (Sensitivity): 0.8276\n",
            "Specificity: 0.9727\n",
            "F1-score: 0.7680\n",
            "AUC-ROC: 0.9822\n",
            "AUPRC: 0.8595\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.9671 ± 0.0051\n",
            "Precision: 0.7684 ± 0.0517\n",
            "Recall (Sensitivity): 0.8281 ± 0.0131\n",
            "Specificity: 0.9787 ± 0.0063\n",
            "F1-score: 0.7962 ± 0.0231\n",
            "AUC-ROC: 0.9850 ± 0.0021\n",
            "AUPRC: 0.8920 ± 0.0247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LGBM"
      ],
      "metadata": {
        "id": "1MyUP931WR2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.0005, num_leaves=31, random_state=42)\n",
        "\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acrfVJxUWSpr",
        "outputId": "3a34a8d9-c0a7-4d53-9f56-ae39bb01560c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 232})\n",
            "After SMOTE-Tomek:  Counter({0: 2775, 1: 2775})\n",
            "[LightGBM] [Info] Number of positive: 2775, number of negative: 2775\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001197 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1614\n",
            "[LightGBM] [Info] Number of data points in the train set: 5550, number of used features: 23\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "\n",
            "Confusion Matrix:\n",
            "[[691   5]\n",
            " [  1  58]]\n",
            "Accuracy: 0.9921\n",
            "Precision: 0.9206\n",
            "Recall (Sensitivity): 0.9831\n",
            "Specificity: 0.9928\n",
            "F1-score: 0.9508\n",
            "AUC-ROC: 0.9979\n",
            "AUPRC: 0.9577\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2778, 1: 2778})\n",
            "[LightGBM] [Info] Number of positive: 2778, number of negative: 2778\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001487 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1608\n",
            "[LightGBM] [Info] Number of data points in the train set: 5556, number of used features: 23\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "\n",
            "Confusion Matrix:\n",
            "[[693   3]\n",
            " [  0  58]]\n",
            "Accuracy: 0.9960\n",
            "Precision: 0.9508\n",
            "Recall (Sensitivity): 1.0000\n",
            "Specificity: 0.9957\n",
            "F1-score: 0.9748\n",
            "AUC-ROC: 0.9986\n",
            "AUPRC: 0.9641\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2777, 1: 2777})\n",
            "[LightGBM] [Info] Number of positive: 2777, number of negative: 2777\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001287 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1609\n",
            "[LightGBM] [Info] Number of data points in the train set: 5554, number of used features: 23\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "\n",
            "Confusion Matrix:\n",
            "[[689   7]\n",
            " [  2  56]]\n",
            "Accuracy: 0.9881\n",
            "Precision: 0.8889\n",
            "Recall (Sensitivity): 0.9655\n",
            "Specificity: 0.9899\n",
            "F1-score: 0.9256\n",
            "AUC-ROC: 0.9942\n",
            "AUPRC: 0.8915\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "[LightGBM] [Info] Number of positive: 2779, number of negative: 2779\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000948 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1613\n",
            "[LightGBM] [Info] Number of data points in the train set: 5558, number of used features: 23\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "\n",
            "Confusion Matrix:\n",
            "[[690   6]\n",
            " [  3  55]]\n",
            "Accuracy: 0.9881\n",
            "Precision: 0.9016\n",
            "Recall (Sensitivity): 0.9483\n",
            "Specificity: 0.9914\n",
            "F1-score: 0.9244\n",
            "AUC-ROC: 0.9806\n",
            "AUPRC: 0.9267\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "[LightGBM] [Info] Number of positive: 2779, number of negative: 2779\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001000 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1612\n",
            "[LightGBM] [Info] Number of data points in the train set: 5558, number of used features: 23\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "\n",
            "Confusion Matrix:\n",
            "[[689   7]\n",
            " [  3  55]]\n",
            "Accuracy: 0.9867\n",
            "Precision: 0.8871\n",
            "Recall (Sensitivity): 0.9483\n",
            "Specificity: 0.9899\n",
            "F1-score: 0.9167\n",
            "AUC-ROC: 0.9962\n",
            "AUPRC: 0.9292\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.9902 ± 0.0038\n",
            "Precision: 0.9098 ± 0.0265\n",
            "Recall (Sensitivity): 0.9690 ± 0.0225\n",
            "Specificity: 0.9920 ± 0.0024\n",
            "F1-score: 0.9385 ± 0.0240\n",
            "AUC-ROC: 0.9935 ± 0.0074\n",
            "AUPRC: 0.9338 ± 0.0289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CB"
      ],
      "metadata": {
        "id": "7dZDD4k7WWXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSF72erZWW6-",
        "outputId": "c38e75fe-fff1-49ff-83c0-47239c78011b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.12/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24->catboost) (2025.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.3.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (9.1.2)\n",
            "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = CatBoostClassifier(\n",
        "      iterations=100,\n",
        "      learning_rate=0.005,\n",
        "      depth=7,\n",
        "      random_state=42,\n",
        "      verbose=0  # Suppress verbose output\n",
        "  )\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmYujle8WarY",
        "outputId": "b0bada42-2d8f-4801-bb1b-14834ea168ad"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 232})\n",
            "After SMOTE-Tomek:  Counter({0: 2775, 1: 2775})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[690   6]\n",
            " [  0  59]]\n",
            "Accuracy: 0.9921\n",
            "Precision: 0.9077\n",
            "Recall (Sensitivity): 1.0000\n",
            "Specificity: 0.9914\n",
            "F1-score: 0.9516\n",
            "AUC-ROC: 0.9999\n",
            "AUPRC: 0.9987\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2778, 1: 2778})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[694   2]\n",
            " [  1  57]]\n",
            "Accuracy: 0.9960\n",
            "Precision: 0.9661\n",
            "Recall (Sensitivity): 0.9828\n",
            "Specificity: 0.9971\n",
            "F1-score: 0.9744\n",
            "AUC-ROC: 0.9999\n",
            "AUPRC: 0.9988\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2777, 1: 2777})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[689   7]\n",
            " [  0  58]]\n",
            "Accuracy: 0.9907\n",
            "Precision: 0.8923\n",
            "Recall (Sensitivity): 1.0000\n",
            "Specificity: 0.9899\n",
            "F1-score: 0.9431\n",
            "AUC-ROC: 0.9977\n",
            "AUPRC: 0.9668\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[688   8]\n",
            " [  2  56]]\n",
            "Accuracy: 0.9867\n",
            "Precision: 0.8750\n",
            "Recall (Sensitivity): 0.9655\n",
            "Specificity: 0.9885\n",
            "F1-score: 0.9180\n",
            "AUC-ROC: 0.9975\n",
            "AUPRC: 0.9826\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[689   7]\n",
            " [  1  57]]\n",
            "Accuracy: 0.9894\n",
            "Precision: 0.8906\n",
            "Recall (Sensitivity): 0.9828\n",
            "Specificity: 0.9899\n",
            "F1-score: 0.9344\n",
            "AUC-ROC: 0.9972\n",
            "AUPRC: 0.9475\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.9910 ± 0.0034\n",
            "Precision: 0.9063 ± 0.0354\n",
            "Recall (Sensitivity): 0.9862 ± 0.0144\n",
            "Specificity: 0.9914 ± 0.0034\n",
            "F1-score: 0.9443 ± 0.0209\n",
            "AUC-ROC: 0.9984 ± 0.0013\n",
            "AUPRC: 0.9789 ± 0.0220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BNB"
      ],
      "metadata": {
        "id": "a3KtC740WhuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = BernoulliNB()\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dx00Fxe-Wicu",
        "outputId": "20455706-0466-455e-8269-bb755f208932"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 232})\n",
            "After SMOTE-Tomek:  Counter({0: 2775, 1: 2775})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[563 133]\n",
            " [ 11  48]]\n",
            "Accuracy: 0.8093\n",
            "Precision: 0.2652\n",
            "Recall (Sensitivity): 0.8136\n",
            "Specificity: 0.8089\n",
            "F1-score: 0.4000\n",
            "AUC-ROC: 0.8923\n",
            "AUPRC: 0.6659\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2778, 1: 2778})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[560 136]\n",
            " [ 22  36]]\n",
            "Accuracy: 0.7905\n",
            "Precision: 0.2093\n",
            "Recall (Sensitivity): 0.6207\n",
            "Specificity: 0.8046\n",
            "F1-score: 0.3130\n",
            "AUC-ROC: 0.7793\n",
            "AUPRC: 0.4433\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2777, 1: 2777})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[564 132]\n",
            " [ 15  43]]\n",
            "Accuracy: 0.8050\n",
            "Precision: 0.2457\n",
            "Recall (Sensitivity): 0.7414\n",
            "Specificity: 0.8103\n",
            "F1-score: 0.3691\n",
            "AUC-ROC: 0.8386\n",
            "AUPRC: 0.6103\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[549 147]\n",
            " [ 19  39]]\n",
            "Accuracy: 0.7798\n",
            "Precision: 0.2097\n",
            "Recall (Sensitivity): 0.6724\n",
            "Specificity: 0.7888\n",
            "F1-score: 0.3197\n",
            "AUC-ROC: 0.8432\n",
            "AUPRC: 0.5186\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[565 131]\n",
            " [ 28  30]]\n",
            "Accuracy: 0.7891\n",
            "Precision: 0.1863\n",
            "Recall (Sensitivity): 0.5172\n",
            "Specificity: 0.8118\n",
            "F1-score: 0.2740\n",
            "AUC-ROC: 0.7671\n",
            "AUPRC: 0.4270\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.7947 ± 0.0121\n",
            "Precision: 0.2232 ± 0.0316\n",
            "Recall (Sensitivity): 0.6731 ± 0.1134\n",
            "Specificity: 0.8049 ± 0.0094\n",
            "F1-score: 0.3352 ± 0.0496\n",
            "AUC-ROC: 0.8241 ± 0.0512\n",
            "AUPRC: 0.5330 ± 0.1039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNB"
      ],
      "metadata": {
        "id": "6jey5PCQWl6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = MinMaxScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = ComplementNB()\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7CzhNc_WmlF",
        "outputId": "c002a15c-ce6b-41e9-e883-c112511c2b35"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 232})\n",
            "After SMOTE-Tomek:  Counter({0: 2775, 1: 2775})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[290 406]\n",
            " [  8  51]]\n",
            "Accuracy: 0.4517\n",
            "Precision: 0.1116\n",
            "Recall (Sensitivity): 0.8644\n",
            "Specificity: 0.4167\n",
            "F1-score: 0.1977\n",
            "AUC-ROC: 0.8249\n",
            "AUPRC: 0.6517\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2778, 1: 2778})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[281 415]\n",
            " [ 13  45]]\n",
            "Accuracy: 0.4324\n",
            "Precision: 0.0978\n",
            "Recall (Sensitivity): 0.7759\n",
            "Specificity: 0.4037\n",
            "F1-score: 0.1737\n",
            "AUC-ROC: 0.7076\n",
            "AUPRC: 0.4443\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2777, 1: 2777})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[304 392]\n",
            " [ 21  37]]\n",
            "Accuracy: 0.4523\n",
            "Precision: 0.0862\n",
            "Recall (Sensitivity): 0.6379\n",
            "Specificity: 0.4368\n",
            "F1-score: 0.1520\n",
            "AUC-ROC: 0.6763\n",
            "AUPRC: 0.4713\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[296 400]\n",
            " [ 14  44]]\n",
            "Accuracy: 0.4509\n",
            "Precision: 0.0991\n",
            "Recall (Sensitivity): 0.7586\n",
            "Specificity: 0.4253\n",
            "F1-score: 0.1753\n",
            "AUC-ROC: 0.7706\n",
            "AUPRC: 0.5579\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[297 399]\n",
            " [ 18  40]]\n",
            "Accuracy: 0.4469\n",
            "Precision: 0.0911\n",
            "Recall (Sensitivity): 0.6897\n",
            "Specificity: 0.4267\n",
            "F1-score: 0.1610\n",
            "AUC-ROC: 0.6658\n",
            "AUPRC: 0.3895\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.4468 ± 0.0083\n",
            "Precision: 0.0972 ± 0.0096\n",
            "Recall (Sensitivity): 0.7453 ± 0.0865\n",
            "Specificity: 0.4218 ± 0.0124\n",
            "F1-score: 0.1719 ± 0.0173\n",
            "AUC-ROC: 0.7290 ± 0.0674\n",
            "AUPRC: 0.5030 ± 0.1030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNB"
      ],
      "metadata": {
        "id": "17H1Kwu7WqM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = MinMaxScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = MultinomialNB()\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IZ7MoyIWq6s",
        "outputId": "8b0a06e3-522b-4276-9a99-72076a808548"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 232})\n",
            "After SMOTE-Tomek:  Counter({0: 2775, 1: 2775})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[290 406]\n",
            " [  8  51]]\n",
            "Accuracy: 0.4517\n",
            "Precision: 0.1116\n",
            "Recall (Sensitivity): 0.8644\n",
            "Specificity: 0.4167\n",
            "F1-score: 0.1977\n",
            "AUC-ROC: 0.8249\n",
            "AUPRC: 0.6517\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2778, 1: 2778})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[281 415]\n",
            " [ 13  45]]\n",
            "Accuracy: 0.4324\n",
            "Precision: 0.0978\n",
            "Recall (Sensitivity): 0.7759\n",
            "Specificity: 0.4037\n",
            "F1-score: 0.1737\n",
            "AUC-ROC: 0.7076\n",
            "AUPRC: 0.4443\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2777, 1: 2777})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[304 392]\n",
            " [ 21  37]]\n",
            "Accuracy: 0.4523\n",
            "Precision: 0.0862\n",
            "Recall (Sensitivity): 0.6379\n",
            "Specificity: 0.4368\n",
            "F1-score: 0.1520\n",
            "AUC-ROC: 0.6763\n",
            "AUPRC: 0.4713\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[296 400]\n",
            " [ 14  44]]\n",
            "Accuracy: 0.4509\n",
            "Precision: 0.0991\n",
            "Recall (Sensitivity): 0.7586\n",
            "Specificity: 0.4253\n",
            "F1-score: 0.1753\n",
            "AUC-ROC: 0.7706\n",
            "AUPRC: 0.5579\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[297 399]\n",
            " [ 18  40]]\n",
            "Accuracy: 0.4469\n",
            "Precision: 0.0911\n",
            "Recall (Sensitivity): 0.6897\n",
            "Specificity: 0.4267\n",
            "F1-score: 0.1610\n",
            "AUC-ROC: 0.6658\n",
            "AUPRC: 0.3895\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.4468 ± 0.0083\n",
            "Precision: 0.0972 ± 0.0096\n",
            "Recall (Sensitivity): 0.7453 ± 0.0865\n",
            "Specificity: 0.4218 ± 0.0124\n",
            "F1-score: 0.1719 ± 0.0173\n",
            "AUC-ROC: 0.7290 ± 0.0674\n",
            "AUPRC: 0.5030 ± 0.1030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "HGB"
      ],
      "metadata": {
        "id": "QE9owXrqWuh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = HistGradientBoostingClassifier(\n",
        "        max_iter=100,\n",
        "        learning_rate=0.5,\n",
        "        max_depth=5,\n",
        "        random_state=42\n",
        "    )\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTd0L0ODWvMn",
        "outputId": "2cf37e87-d017-4480-ed13-c32462f02684"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 232})\n",
            "After SMOTE-Tomek:  Counter({0: 2775, 1: 2775})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[320 376]\n",
            " [  5  54]]\n",
            "Accuracy: 0.4954\n",
            "Precision: 0.1256\n",
            "Recall (Sensitivity): 0.9153\n",
            "Specificity: 0.4598\n",
            "F1-score: 0.2209\n",
            "AUC-ROC: 0.6913\n",
            "AUPRC: 0.1224\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2778, 1: 2778})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[694   2]\n",
            " [  1  57]]\n",
            "Accuracy: 0.9960\n",
            "Precision: 0.9661\n",
            "Recall (Sensitivity): 0.9828\n",
            "Specificity: 0.9971\n",
            "F1-score: 0.9744\n",
            "AUC-ROC: 0.9999\n",
            "AUPRC: 0.9991\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2777, 1: 2777})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[692   4]\n",
            " [  0  58]]\n",
            "Accuracy: 0.9947\n",
            "Precision: 0.9355\n",
            "Recall (Sensitivity): 1.0000\n",
            "Specificity: 0.9943\n",
            "F1-score: 0.9667\n",
            "AUC-ROC: 0.9979\n",
            "AUPRC: 0.9547\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[693   3]\n",
            " [  4  54]]\n",
            "Accuracy: 0.9907\n",
            "Precision: 0.9474\n",
            "Recall (Sensitivity): 0.9310\n",
            "Specificity: 0.9957\n",
            "F1-score: 0.9391\n",
            "AUC-ROC: 0.9760\n",
            "AUPRC: 0.9658\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[692   4]\n",
            " [  1  57]]\n",
            "Accuracy: 0.9934\n",
            "Precision: 0.9344\n",
            "Recall (Sensitivity): 0.9828\n",
            "Specificity: 0.9943\n",
            "F1-score: 0.9580\n",
            "AUC-ROC: 0.9973\n",
            "AUPRC: 0.9252\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.8940 ± 0.2229\n",
            "Precision: 0.7818 ± 0.3671\n",
            "Recall (Sensitivity): 0.9624 ± 0.0369\n",
            "Specificity: 0.8882 ± 0.2395\n",
            "F1-score: 0.8118 ± 0.3306\n",
            "AUC-ROC: 0.9325 ± 0.1352\n",
            "AUPRC: 0.7935 ± 0.3761\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NC"
      ],
      "metadata": {
        "id": "thoV59fhWy6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import NearestCentroid\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, accuracy_score, precision_score,\n",
        "    recall_score, f1_score, roc_auc_score,\n",
        "    average_precision_score\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target column as Series (0/1)\n",
        "# Example:\n",
        "# X = df.drop(\"Recurred\", axis=1)\n",
        "# y = df[\"Recurred\"]\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", Counter(y_train))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", Counter(y_train_res))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Logistic Regression\n",
        "    # =========================\n",
        "    model = NearestCentroid()\n",
        "    model.fit(X_train_scaled, y_train_res)\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Print metrics\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# Cross-Validation Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8IxFv83Wzn_",
        "outputId": "eeb7ebbe-0bc1-4c8e-cbf5-5d7810675c2b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 232})\n",
            "After SMOTE-Tomek:  Counter({0: 2775, 1: 2775})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[551 145]\n",
            " [ 17  42]]\n",
            "Accuracy: 0.7854\n",
            "Precision: 0.2246\n",
            "Recall (Sensitivity): 0.7119\n",
            "Specificity: 0.7917\n",
            "F1-score: 0.3415\n",
            "AUC-ROC: 0.8675\n",
            "AUPRC: 0.5847\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2778, 1: 2778})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[550 146]\n",
            " [ 22  36]]\n",
            "Accuracy: 0.7772\n",
            "Precision: 0.1978\n",
            "Recall (Sensitivity): 0.6207\n",
            "Specificity: 0.7902\n",
            "F1-score: 0.3000\n",
            "AUC-ROC: 0.7931\n",
            "AUPRC: 0.4609\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2777, 1: 2777})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[559 137]\n",
            " [ 16  42]]\n",
            "Accuracy: 0.7971\n",
            "Precision: 0.2346\n",
            "Recall (Sensitivity): 0.7241\n",
            "Specificity: 0.8032\n",
            "F1-score: 0.3544\n",
            "AUC-ROC: 0.8417\n",
            "AUPRC: 0.5398\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[560 136]\n",
            " [ 19  39]]\n",
            "Accuracy: 0.7944\n",
            "Precision: 0.2229\n",
            "Recall (Sensitivity): 0.6724\n",
            "Specificity: 0.8046\n",
            "F1-score: 0.3348\n",
            "AUC-ROC: 0.8559\n",
            "AUPRC: 0.5584\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: Counter({0: 2784, 1: 233})\n",
            "After SMOTE-Tomek:  Counter({0: 2779, 1: 2779})\n",
            "\n",
            "Confusion Matrix:\n",
            "[[565 131]\n",
            " [ 27  31]]\n",
            "Accuracy: 0.7905\n",
            "Precision: 0.1914\n",
            "Recall (Sensitivity): 0.5345\n",
            "Specificity: 0.8118\n",
            "F1-score: 0.2818\n",
            "AUC-ROC: 0.8004\n",
            "AUPRC: 0.4056\n",
            "\n",
            "=========== 5-Fold CV Summary ===========\n",
            "\n",
            "Accuracy: 0.7889 ± 0.0079\n",
            "Precision: 0.2143 ± 0.0187\n",
            "Recall (Sensitivity): 0.6527 ± 0.0774\n",
            "Specificity: 0.8003 ± 0.0091\n",
            "F1-score: 0.3225 ± 0.0304\n",
            "AUC-ROC: 0.8317 ± 0.0333\n",
            "AUPRC: 0.5099 ± 0.0744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANN"
      ],
      "metadata": {
        "id": "NWi44_ZXW3g3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Required Libraries\n",
        "# =========================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, average_precision_score, confusion_matrix\n",
        ")\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# =========================\n",
        "# Features & Target\n",
        "# =========================\n",
        "# X -> after one-hot encoding\n",
        "# y -> target Series (0/1)\n",
        "\n",
        "# =========================\n",
        "# Stratified 5-Fold CV\n",
        "# =========================\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold = 1\n",
        "all_metrics = []\n",
        "\n",
        "# =========================\n",
        "# CV Loop\n",
        "# =========================\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "\n",
        "    print(f\"\\n================ Fold {fold} =================\")\n",
        "\n",
        "    # Split\n",
        "    X_train_raw, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train_raw, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    print(\"Before SMOTE-Tomek:\", dict(pd.Series(y_train_raw).value_counts()))\n",
        "\n",
        "    # =========================\n",
        "    # SMOTE-Tomek (TRAIN ONLY)\n",
        "    # =========================\n",
        "    smt = SMOTETomek(random_state=42)\n",
        "    X_train_res, y_train_res = smt.fit_resample(X_train_raw, y_train_raw)\n",
        "\n",
        "    print(\"After SMOTE-Tomek: \", dict(pd.Series(y_train_res).value_counts()))\n",
        "\n",
        "    # =========================\n",
        "    # Feature Scaling\n",
        "    # =========================\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_res)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # =========================\n",
        "    # Build ANN\n",
        "    # =========================\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "        Dropout(0.3),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=10,\n",
        "        restore_best_weights=True,\n",
        "        verbose=0\n",
        "    )\n",
        "    reduce_lr = ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        min_lr=1e-6,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        X_train_scaled, y_train_res,\n",
        "        epochs=300,\n",
        "        batch_size=32,\n",
        "        validation_split=0.2,\n",
        "        callbacks=[early_stop, reduce_lr],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # =========================\n",
        "    # Predictions\n",
        "    # =========================\n",
        "    y_proba = model.predict(X_test_scaled).ravel()\n",
        "    y_pred = (y_proba >= 0.8).astype(int)\n",
        "\n",
        "    # =========================\n",
        "    # Confusion Matrix\n",
        "    # =========================\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # =========================\n",
        "    # Metrics\n",
        "    # =========================\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision\": precision_score(y_test, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_test, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else 0,\n",
        "        \"F1-score\": f1_score(y_test, y_pred),\n",
        "        \"AUC-ROC\": roc_auc_score(y_test, y_proba),\n",
        "        \"AUPRC\": average_precision_score(y_test, y_proba)\n",
        "    }\n",
        "\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# =========================\n",
        "# CV Summary\n",
        "# =========================\n",
        "metrics_df = pd.DataFrame(all_metrics)\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"Mean\": metrics_df.mean(),\n",
        "    \"Std\": metrics_df.std()\n",
        "})\n",
        "\n",
        "print(\"\\n=========== 5-Fold CV Summary (ANN) ===========\\n\")\n",
        "for metric in summary.index:\n",
        "    print(f\"{metric}: {summary.loc[metric,'Mean']:.4f} ± {summary.loc[metric,'Std']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcLzijWHW4RV",
        "outputId": "81d4067a-f733-41c0-a177-f2e16ccdd356"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================ Fold 1 =================\n",
            "Before SMOTE-Tomek: {0: np.int64(2784), 1: np.int64(232)}\n",
            "After SMOTE-Tomek:  {0: np.int64(2775), 1: np.int64(2775)}\n",
            "\n",
            "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 63: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[694   2]\n",
            " [  4  55]]\n",
            "Accuracy: 0.9921\n",
            "Precision: 0.9649\n",
            "Recall (Sensitivity): 0.9322\n",
            "Specificity: 0.9971\n",
            "F1-score: 0.9483\n",
            "AUC-ROC: 0.9988\n",
            "AUPRC: 0.9870\n",
            "\n",
            "================ Fold 2 =================\n",
            "Before SMOTE-Tomek: {0: np.int64(2784), 1: np.int64(233)}\n",
            "After SMOTE-Tomek:  {0: np.int64(2778), 1: np.int64(2778)}\n",
            "\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[693   3]\n",
            " [ 11  47]]\n",
            "Accuracy: 0.9814\n",
            "Precision: 0.9400\n",
            "Recall (Sensitivity): 0.8103\n",
            "Specificity: 0.9957\n",
            "F1-score: 0.8704\n",
            "AUC-ROC: 0.9945\n",
            "AUPRC: 0.9388\n",
            "\n",
            "================ Fold 3 =================\n",
            "Before SMOTE-Tomek: {0: np.int64(2784), 1: np.int64(233)}\n",
            "After SMOTE-Tomek:  {0: np.int64(2777), 1: np.int64(2777)}\n",
            "\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[695   1]\n",
            " [ 10  48]]\n",
            "Accuracy: 0.9854\n",
            "Precision: 0.9796\n",
            "Recall (Sensitivity): 0.8276\n",
            "Specificity: 0.9986\n",
            "F1-score: 0.8972\n",
            "AUC-ROC: 0.9654\n",
            "AUPRC: 0.9434\n",
            "\n",
            "================ Fold 4 =================\n",
            "Before SMOTE-Tomek: {0: np.int64(2784), 1: np.int64(233)}\n",
            "After SMOTE-Tomek:  {0: np.int64(2779), 1: np.int64(2779)}\n",
            "\n",
            "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[691   5]\n",
            " [  8  50]]\n",
            "Accuracy: 0.9828\n",
            "Precision: 0.9091\n",
            "Recall (Sensitivity): 0.8621\n",
            "Specificity: 0.9928\n",
            "F1-score: 0.8850\n",
            "AUC-ROC: 0.9654\n",
            "AUPRC: 0.9130\n",
            "\n",
            "================ Fold 5 =================\n",
            "Before SMOTE-Tomek: {0: np.int64(2784), 1: np.int64(233)}\n",
            "After SMOTE-Tomek:  {0: np.int64(2779), 1: np.int64(2779)}\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 46: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\n",
            "Epoch 51: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "Confusion Matrix:\n",
            "[[693   3]\n",
            " [ 16  42]]\n",
            "Accuracy: 0.9748\n",
            "Precision: 0.9333\n",
            "Recall (Sensitivity): 0.7241\n",
            "Specificity: 0.9957\n",
            "F1-score: 0.8155\n",
            "AUC-ROC: 0.9485\n",
            "AUPRC: 0.8656\n",
            "\n",
            "=========== 5-Fold CV Summary (ANN) ===========\n",
            "\n",
            "Accuracy: 0.9833 ± 0.0063\n",
            "Precision: 0.9454 ± 0.0276\n",
            "Recall (Sensitivity): 0.8313 ± 0.0759\n",
            "Specificity: 0.9960 ± 0.0021\n",
            "F1-score: 0.8833 ± 0.0479\n",
            "AUC-ROC: 0.9745 ± 0.0214\n",
            "AUPRC: 0.9296 ± 0.0446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('ann_model.keras')"
      ],
      "metadata": {
        "id": "FYPcbSq9Jszn"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}